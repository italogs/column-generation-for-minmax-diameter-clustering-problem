{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Solver for Problem 1 (Clique Clustering Model - G=(V,E))\n",
    "\n",
    "### Ítalo Gomes Santana, Rafael Azevedo e Rodrigo Laigner\n",
    "\n",
    "### Pontifical Catholic University of Rio de Janeiro (PUC-RIO) 2018.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import time as tm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from gurobipy import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Loading and Initialization of the Input Graph for Problem 1 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Instance\n",
    "def read_graph(file_name):\n",
    "    \n",
    "    print(\"\\nLoading instance from file: \", file_name)\n",
    "    f = open(file_name,'r+')\n",
    "    \n",
    "    vmap = {}\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        \n",
    "        # Ignore comment lines and blocks in the file.\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "\n",
    "        # Read a line containing two integers, representing the two vertices of an edge.\n",
    "        item_data = line.split()\n",
    "        if len(item_data) != 2:\n",
    "            # Invalid line data: \n",
    "            continue\n",
    "\n",
    "        # Get the first vertex of the edge\n",
    "        i = int(item_data[0])\n",
    "        # Get the second vertex of the edge\n",
    "        j = int(item_data[1])\n",
    "\n",
    "        # Map each read vertex to a position of the vmap array, setting a unique integer to each vertex.\n",
    "        if i not in vmap:\n",
    "            vmap[i] = len(vmap) + 1\n",
    "        if j not in vmap:\n",
    "            vmap[j] = len(vmap) + 1\n",
    "\n",
    "        # Set the source vertex index of the edge as the one mapped to the minimum integer.\n",
    "        # Set the sink vertex index of the edge as the one mapped to the maximum integer.\n",
    "        source = min(vmap[i], vmap[j])\n",
    "        sink   = max(vmap[i], vmap[j])\n",
    "        \n",
    "        # Compute edges ignoring loops because distance is 0.\n",
    "        # Edges weights are set as 1 by default.\n",
    "        if source != sink and (source,sink) not in graph.edges(): \n",
    "            graph.add_edge(source, sink, weight=1)\n",
    "\n",
    "    #print(vmap)\n",
    "    f.close()\n",
    "    \n",
    "    V = { index:vertex for vertex,index in vmap.items() }\n",
    "    \n",
    "    print(\"N vértices: \", len(V))\n",
    "    print(\"M edges: \", len(graph.edges()))\n",
    "    \n",
    "    # FOR DEBUG PURPOSES ONLY.\n",
    "    #print(\"\\nVertices: \\n {}\\n\".format(graph.nodes()))\n",
    "    #print(\"\\nEdges: \\n {}\\n\".format(graph.edges()))\n",
    "    #print(\"\\nEdges with weights: \\n {}\\n\".format(graph.edges(data='weight')))\n",
    "    #print(vmap.keys())\n",
    "    \n",
    "    return len(V), len(graph.edges()), vmap, graph, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(V,E):\n",
    "    n = len(V)\n",
    "    adjs = {}\n",
    "    \n",
    "    for v in V:\n",
    "        adjs[v] = []\n",
    "    \n",
    "    # Compute the edge adjacency list for each vertex.\n",
    "    for e in E:\n",
    "        adjs[e[0]].append(e[1])\n",
    "        adjs[e[1]].append(e[0])\n",
    "\n",
    "    n = len(V)\n",
    "    dist = {}\n",
    "\n",
    "    # BFS to compute the minimum distance between each edge (v, s) for all vertices v, s of V. \n",
    "    for v in V:\n",
    "        L=[v]\n",
    "        dist[v,v]=0\n",
    "        # While the frontier is not empty, continue BFS.\n",
    "        while( len(L) > 0 ):\n",
    "            c = L[0]\n",
    "            L.remove(c)\n",
    "            for s in adjs[c]:\n",
    "                if ( (v,s) not in dist ):\n",
    "                    dist[v,s] = dist[v,c] + 1\n",
    "                    L.append(s)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically a reverse map of vertices of an edge.\n",
    "def getEdgeMapping(source, sink, vmap):\n",
    "    return (vmap[source],vmap[sink])\n",
    "\n",
    "# Get the edge vertices integer indexed by a unique integer.\n",
    "# Basically a reverse map of vertices of an edge for every edge in E.\n",
    "def remap_edges(E,V):\n",
    "    return  [ (V[i],V[j]) for i,j in E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeGraph(graph, layout_attr='circular', color_map=None, scale=10, enable_edges=True, node_size=30):\n",
    "    \n",
    "    layout = None\n",
    "    \n",
    "    if(layout_attr==\"bipartite\"):\n",
    "        # Position nodes in two straight lines.\n",
    "        print(\"\\nBipartite Graph: \")\n",
    "        layout = nx.bipartite_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"circular\"):\n",
    "        # Position nodes on a circle.\n",
    "        print(\"\\Circular Graph: \")\n",
    "        layout = nx.circular_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"kamada_kawai\"):\n",
    "        # Position nodes using Kamada-Kawai path-length cost-function.\n",
    "        print(\"\\Kamada-kawai Graph: \")\n",
    "        layout = nx.kamada_kawai_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"random\"):\n",
    "        # Position nodes uniformly at random in the unit square.\n",
    "        print(\"\\Random Graph: \")\n",
    "        layout = nx.random_layout(graph)\n",
    "    elif(layout_attr==\"rescale\"):\n",
    "        # Return scaled position array to (-scale, scale) in all axes.\n",
    "        print(\"\\Rescale Graph: \")\n",
    "        layout = nx.rescale_layout(graph)\n",
    "    elif(layout_attr==\"shell\"):\n",
    "        # Position nodes in concentric circles.\n",
    "        print(\"\\Shell Graph: \")\n",
    "        layout = nx.shell_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"spring\"):\n",
    "        #Position nodes using Fruchterman-Reingold force-directed algorithm.\n",
    "        print(\"\\Spring Graph: \")\n",
    "        layout = nx.spring_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"spectral\"):\n",
    "        # Position nodes using the eigenvectors of the graph Laplacian.\n",
    "        print(\"\\nSpectral Graph: \")\n",
    "        layout = nx.spectral_layout(graph, scale=scale)\n",
    "    else:\n",
    "        layout = nx.random_layout(graph, scale=scale)\n",
    "    \n",
    "    nx.draw_networkx_nodes(graph, layout)\n",
    "    \n",
    "    edge_labels = dict([((u,v,),d[ 'weight']) for u,v,d in graph.edges(data=True)])\n",
    "    \n",
    "    #nx.draw_networkx_labels(graph, layout, font_size=20, font_family='sans-serif')\n",
    "    if(enable_edges):\n",
    "        nx.draw_networkx_edges(graph, layout)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.figure(3,figsize=(12,12))\n",
    "    \n",
    "    #nx.draw_networkx_edge_labels(graph, layout, edge_labels=edge_labels)\n",
    "    \n",
    "    if color_map != None:\n",
    "        nx.draw(graph, layout, edge_cmap=plt.cm.Reds, node_size=node_size,font_size=8, node_color=color_map)\n",
    "    else:\n",
    "        nx.draw(graph, layout, edge_cmap=plt.cm.Reds, node_size=node_size,font_size=8)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGraphInstance(file_name):\n",
    "    n, m, vmap, graph, V = read_graph(file_name)\n",
    "    dist = compute_distances(list(V.keys()), graph.edges())\n",
    "    \n",
    "    # FOR DEBUG PURPOSES ONLY.\n",
    "    #print(\"VERTICES:\\n\")\n",
    "    #print(V)\n",
    "    #print(\"VMAP:\\n\")\n",
    "    #print(vmap)\n",
    "    #print(\"EDGES:\\n\")\n",
    "    #print(graph.edges())\n",
    "\n",
    "    E = remap_edges(graph.edges(), V)\n",
    "\n",
    "    # FOR DEBUG PURPOSES ONLY\n",
    "    #print(\"REVERSE MAPPED EDGES:\\n\")\n",
    "    #print(E)\n",
    "    #print(\"MINIMUM DISTANCE BETWEEN VERTICES:\\n\")\n",
    "    #print(dist)\n",
    "    \n",
    "    return n, m, V, E, vmap, graph, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ######################################### FOR DEBUG PURPOSES ONLY #################################################\n",
    "\n",
    "# n, m, V, E, vmap, graph, dist = loadGraphInstance(\"tvshow_edges_shorter.txt\")\n",
    "\n",
    "# print(\"\\nEncoded N: \", n, \"- Vertices:\", graph.nodes())\n",
    "# print(\"\\nEncoded M: \", m, \"- Edges:\", graph.edges())\n",
    "\n",
    "# print(\"\\nN:\", n, \"- V:\", V)\n",
    "# print(\"\\nM:\", m, \"- E:\", E)\n",
    "\n",
    "# scale = 1000\n",
    "# en_edges = False\n",
    "\n",
    "# print(\"\\nCircular Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='circular', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nKamada Kawai Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='kamada_kawai', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nRandom Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='random', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nShell Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='shell', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nSpring Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='spring', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nSpectral Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='spectral', scale=scale, enable_edges=en_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulação para o Problema 1 (Clique Clustering Model - G=(V,E))\n",
    "\n",
    "$$\n",
    "{\\large\n",
    "\\begin{array}{rll}\n",
    "\\min  &  \\sum\\limits_{k=1}^{n} z_k &\\\\\n",
    "s.t. & & \\\\\n",
    " & y_{vk} + y_{wk} \\leq 1  &\\quad  d(v,w) > H + 1 \\quad \\forall k= 1,\\ldots, n \\\\\n",
    " & y_{vk} \\leq z_k & \\quad \\forall v \\in V \\quad \\forall k= 1,\\ldots, n \\> = \\> |V| \\\\\n",
    " & \\sum\\limits_{k=1}^{n} y_{vk} = 1 & \\quad \\forall v \\in V \\\\\n",
    " &  y_{vk} \\in \\{ 0,1 \\} & \\\\\n",
    " &  z_{k} \\in \\{ 0,1 \\} &\n",
    "\\end{array}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Variables for Problem 1 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y_vk variables which represent the belonging of vertex v to the cluster k.\n",
    "# If vertex v belongs to cluster k, then y_vk == 1. Otherwise, y_vk == 0.\n",
    "# Binary decision variable.\n",
    "\n",
    "def create_yvk_vars(model, V):\n",
    "    n = len(V)\n",
    "    \n",
    "    y_vk = {}\n",
    "    \n",
    "    # For each vertex v and cluster k, vertex v belongs to cluster k (y_vk == 1) or not (y_vk == 0).\n",
    "    for k in range(1, n+1):\n",
    "        for v in range(1, n+1):\n",
    "            y_vk[v, k] = model.addVar(obj=0.0, vtype=GRB.BINARY, name\n",
    "                                      ='y_vk'+'_'+str(v)+str(k))\n",
    "    model.update()\n",
    "    return y_vk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create z_k variables which represent the inclusion of cluster k to the set of clusters composing the solution.\n",
    "# If cluster k belongs to the set of disjoint partitions of V, then z_k == 1. Otherwise, z_k == 0.\n",
    "# If z_k == 0, then no vertex is allocated to the cluster k and cluster k is excluded from the solution.\n",
    "\n",
    "def create_zk_vars(model, V):\n",
    "\n",
    "    z_k = {}\n",
    "    \n",
    "    for k in range(1, len(V) + 1):\n",
    "        z_k[k] = model.addVar(obj=1.0, vtype=GRB.BINARY, name='z'+'_'+str(k))\n",
    "    model.update()\n",
    "    return z_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Constraints for Problem 1 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conflict constraints which restricts a pair of vertices (v, w) to belong to the same cluster\n",
    "# only if the minimum distance between these vertices is at most H, a given parameter.\n",
    "# If the minimum distance between vertices v and w is greater than H, then v or w belongs to cluster k\n",
    "# or v, w not in cluster k.\n",
    "\n",
    "def create_conf_constraints(model, y_vk, V, dist, H):\n",
    "\n",
    "    n = len(V)\n",
    "    total = 0\n",
    "    \n",
    "    conf_constr = {}\n",
    "\n",
    "    # y_vk[v, k] == 1 or y_vk[w, k] == 1 or (y_vk[v, k] == 0 and y_vk[w, k] == 0) for each (v, w) and cluster k. \n",
    "    for k in range(1, n+1):\n",
    "        for v in range(1, n):\n",
    "            for w in range(v+1, n+1):\n",
    "                if (((v,w) not in dist) or (dist[v,w] > H)):\n",
    "                    total = total + 1\n",
    "                    constr_name = 'conf_constr_'+str(v)+'_'+str(w)+'_'+str(k)\n",
    "                    conf_constr[v, w, k] = model.addConstr(y_vk[v, k] + y_vk[w, k] <= 1, name=constr_name)\n",
    "    model.update()\n",
    "    print(\"\\nTotal conflict constraints created = \", total)\n",
    "    return conf_constr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create upper bound constraints which restricts y_vk[v, k] to a value equal or less than _k[k].\n",
    "# This restricts vertex v to belong to cluster k only if z_k[k] == 1, that is cluster k exists in the solution.\n",
    "\n",
    "def create_up_constraints(model, y_vk, z_k, V):\n",
    "    n = len(V)\n",
    "    total = 0\n",
    "    up_constrs = {}\n",
    "    \n",
    "    # Restricts vertex v as possibly belonging to cluster k iff cluster k exists in the solution (z_k[k] == 1) \n",
    "    for k in range(1, n + 1):\n",
    "        for v in range(1, n + 1):\n",
    "            total = total + 1\n",
    "            up_constrs[v,k] = model.addConstr(y_vk[v, k] - z_k[k] <= 0, name='up_constr_'+str(v)+'_'+str(k))\n",
    "    \n",
    "    model.update()\n",
    "    print(\"\\nTotal up constraints created = \", total)\n",
    "    return up_constrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Assignment constraints which restricts a vertex to belong only to one cluster at a time.\n",
    "# Each vertex belongs to one and one only cluster because partitions must be disjoint subsets of vertices.\n",
    "\n",
    "def create_asgn_constraints(model, y_vk, V):\n",
    "    n = len(V)\n",
    "    total = 0\n",
    "    asgn_constrs = {}\n",
    "    \n",
    "    # Assure that that exists only one cluster k for which vertex v belongs to, that is y_vk[v, k] == 1. \n",
    "    for v in range(1, n + 1):\n",
    "        total = total + 1\n",
    "        constr_name = 'asgn_constr'+str(v)\n",
    "        asgn_constrs[v] = model.addConstr((quicksum(y_vk[v, k] for k in range(1, n + 1)) == 1), name=constr_name)\n",
    "    \n",
    "    model.update()\n",
    "    print(\"\\nTotal assignment constraints created = \", total)\n",
    "    return asgn_constrs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Primal-Dual Solver for Problem 1 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H => Maximum diameter\n",
    "# timeLimit => integer representing the maximum number of seconds for the solver to find a solution.\n",
    "\n",
    "def solveMinClustersPrimalModel(V, E, vmap, graph, dist, H, timeLimit):\n",
    "    \n",
    "    n = len(V)\n",
    "    m = len(E)\n",
    "    \n",
    "    # Creates the model mp.\n",
    "    mp = Model()\n",
    "    \n",
    "    # Decision binary variables \n",
    "    y_vk = {}\n",
    "    z_k = {}\n",
    "    \n",
    "    # Constraints\n",
    "    conf_constrs = {}\n",
    "    up_constrs = {}\n",
    "    asgn_constrs = {}\n",
    "    \n",
    "    print(\"\\nH (Maximum Diameter) = \", H)\n",
    "    \n",
    "    # Creating and initializing model variables.\n",
    "    \n",
    "    vars_tstart = tm.time()\n",
    "    \n",
    "    # Create variables y_vk for each vertex v and cluster k\n",
    "    # y_vk == 1 => vertex v belongs to cluster k\n",
    "    # y_vk == 0 => vertex v does not belong to cluster k\n",
    "    y_vk = create_yvk_vars(mp, V)\n",
    "    \n",
    "    # Create objective variables z_k for each disjoint cluster k\n",
    "    # z_k = 1 => cluster k exists in the solution.\n",
    "    # z_k = 0 => cluster k does not exist in the solution.\n",
    "    z_k = create_zk_vars(mp, V)\n",
    "    \n",
    "    vars_exec_time = tm.time() - vars_tstart\n",
    "    print(\"\\nVariables created (execution time = {:.4f}s).\".format(vars_exec_time))\n",
    "    \n",
    "    # Creating and initializing model constraints.\n",
    "    \n",
    "    constrs_tstart = tm.time()\n",
    "\n",
    "    # Create constraint for avoiding conflict (vertices farther than H + 1 belong to different cluster).\n",
    "    conf_constrs = create_conf_constraints(mp, y_vk, V, dist, H)\n",
    "    \n",
    "    # Create upper bound constraints (y_vk <= z_k)\n",
    "    up_constrs = create_up_constraints(mp, y_vk, z_k, V)\n",
    "    \n",
    "    # Create assignment constraint (each vertex belongs to one and one only cluster)\n",
    "    asgn_constrs = create_asgn_constraints(mp, y_vk, V)\n",
    "    \n",
    "    constrs_exec_time = tm.time() - constrs_tstart\n",
    "    print(\"\\nConstraints created (execution time = {:.4f}s).\\n\".format(constrs_exec_time))\n",
    "    \n",
    "    # Time limit for searching an optimal solution.\n",
    "    print(\"\\nTimeLimit: {}\\n\".format(timeLimit))\n",
    "    \n",
    "    # Output the mp model definition, including variables and constraints.\n",
    "    mp.write(\"mf_clust.lp\")\n",
    "    \n",
    "    # Set parameters for the mp model.\n",
    "    mp.setParam('TimeLimit', timeLimit)\n",
    "    mp.setParam('OutputFlag', 1)\n",
    "    \n",
    "    print(\"\\n\\n####### SOLVER START #######\\n\")\n",
    "    solver_tstart = tm.time()\n",
    "    mp.optimize()\n",
    "    solver_exec_time = tm.time() - solver_tstart\n",
    "    print(\"\\nSolver finished (execution time = {:.4f}s)\\n\".format(solver_exec_time))\n",
    "    print(\"\\n####### SOLVER END #######\\n\\n\")\n",
    "    \n",
    "    # Get model current objective function.\n",
    "    zp = mp.getObjective()\n",
    "\n",
    "    print(\"TOTAL EXECUTIO# Mapping vertices to their respective cluster according to the optimal solution found by the mp model.N TIME = {:.4f}s\\n\".format(vars_exec_time + constrs_exec_time + solver_exec_time))\n",
    "    \n",
    "    v_sol = mp.getAttr('X', y_vk)\n",
    "    \n",
    "    # FOR DEBUG PURPOSES ONLY.\n",
    "    #print v_sol\n",
    "    \n",
    "    # Retrieve for each vertex the respective cluster to which it belongs to.\n",
    "    v_sol_r = {v:k for v in range(1, n + 1) for k in range(1, n + 1) if v_sol[v,k] > 0.001}\n",
    "    \n",
    "    clusters = {}\n",
    "    \n",
    "    # Mapping vertices to their respective cluster according to the optimal solution found by the mp model.\n",
    "    for v,k in v_sol_r.items():\n",
    "        # Initializes an empty list of vertices of cluster k when cluster k is visited for the first time.\n",
    "        if k not in clusters.keys():\n",
    "            clusters[k] = []\n",
    "        clusters[k].append(v)\n",
    "\n",
    "    return zp.getValue(), v_sol_r, clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Output of Results for Problem 1 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of color shades for each cluster and set the corresponding cluster color to each vertex.\n",
    "\n",
    "def computeColorMap(graph, clusters, vertex_cluster):\n",
    "    assert(isinstance(clusters, dict))\n",
    "    assert(isinstance(vertex_cluster, dict))\n",
    "    \n",
    "    if(not clusters or not vertex_cluster):\n",
    "        return None\n",
    "    \n",
    "    color_map = []\n",
    "    \n",
    "    cmap = cm.autumn\n",
    "    norm = Normalize(vmin=0,vmax=1)\n",
    "\n",
    "    ratio = 1.0 / len(clusters)\n",
    "    k_index = {}\n",
    "    k_counter = 1\n",
    "    for node in graph:\n",
    "        k = vertex_cluster[node]\n",
    "        #print(\"\\tNode: {} => k = {}\".format(node, k))\n",
    "        if k not in k_index.keys():\n",
    "            k_index[k] = k_counter\n",
    "            k_counter += 1\n",
    "        color_map.append(cmap(norm(k_index[k] * ratio)))\n",
    "    \n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSolution(V,zp, vertex_cluster, clusters):\n",
    "    assert(isinstance(vertex_cluster, dict))\n",
    "    assert(isinstance(clusters, dict))\n",
    "    print (\"\\nNúmero de Clusters: \", zp)\n",
    "    \n",
    "    if(vertex_cluster != None and vertex_cluster):\n",
    "        print (\"\\nSolution (vertex_index, k_cluster_index): \\n\\n\\t{}\\n\".format(vertex_cluster))\n",
    "\n",
    "    if(clusters != None and clusters):\n",
    "        for k,vertices in clusters.items():\n",
    "            print(\"\\tCluster #{} contains the following vertices: \\n\".format(k))\n",
    "            line_buffer = 0\n",
    "            for v in vertices:\n",
    "                if(line_buffer == 0):\n",
    "                    print(\"\\t\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]), end = '')\n",
    "                else:\n",
    "                    print(\"\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]), end = '')\n",
    "                line_buffer += 1\n",
    "                if(line_buffer == 3):\n",
    "                    print()\n",
    "                    line_buffer = 0\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Execution of Primal-Dual Algorithm for Problem 1 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Execution of the algorithm to solve problem 1 for a given graph stored in a readable file with path file_path.\n",
    "# file_path : Path of the file containing the edges of the graph.\n",
    "# H : Maximum minimum distance between any two vertices (maximum cluster diameter)\n",
    "# enableVis : If true, plot graph with colored vertices according to the corresponding cluster.\n",
    "\n",
    "def executeMinClustersAlgorithm(file_path, list_H, timeLimit, enableVis):\n",
    "\n",
    "    # Load graph from file and treat data.\n",
    "    n, m, V, E, vmap, graph, dist = loadGraphInstance(file_path)\n",
    "    \n",
    "    for H in list_H:\n",
    "        # Solve the problem of minimizing the number of clusters with diameter less than or equal to H\n",
    "        opt_val, vertex_cluster, clusters = solveMinClustersPrimalModel(V, E, vmap, graph, dist, H, timeLimit)\n",
    "\n",
    "        printSolution(V,opt_val, vertex_cluster, clusters)\n",
    "\n",
    "        # FOR DEBUG PURPOSES ONLY\n",
    "        #print(\"\\nColor Map: \\n\")\n",
    "        #print(\"\\t \", color_map)\n",
    "\n",
    "        if enableVis:\n",
    "            computeColorMap(graph, clusters, vertex_cluster)\n",
    "            # Visualization of the graph. Comment this line for large graphs or when visualizing the clusters is not desired.\n",
    "            visualizeGraph(graph, layout_attr='random', color_map=color_map, scale=1000, enable_edges=True, node_size=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Execute the cell above to use the Primal-Dual algorithm for Problem 1 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to use the algorithm and find optimal solutions for the formulation above.\n",
    "\n",
    "# Path of the file containing the edges of the graph.\n",
    "file_path = \"instances/as19990829.txt\"\n",
    "timeLimit = 60*60*4\n",
    "\n",
    "# file_path = \"instances/as19981229.txt\"\n",
    "# timeLimit = 60*60*6\n",
    "\n",
    "# file_path = \"instances/as19981230.txt\"\n",
    "# timeLimit = 60*60*6\n",
    "\n",
    "\n",
    "# Maximum minimum distance between any two vertices (maximum cluster diameter)\n",
    "list_H = [1, 2, 3, 5, 6]\n",
    "\n",
    "\n",
    "\n",
    "enableVis = False\n",
    "\n",
    "executeMinClustersAlgorithm(file_path, list_H, timeLimit, enableVis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ColGen Formulation - Master Problem\n",
    "\n",
    "$$\n",
    "{\\large\n",
    "\\begin{array}{rll}\n",
    "\\min  &  \\sum\\limits_{p \\in \\cal{P}} \\lambda_p &\\\\\n",
    "s.t. & & \\\\\n",
    "(\\mbox{Dual } \\pi_v) & \\sum\\limits_{p \\in \\cal{P}} a_{vp} . \\lambda_p = 1 & \\quad \\forall v \\in V \\\\\n",
    " &  \\lambda_{p} \\in \\{ 0,1 \\} &\n",
    "\\end{array}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColGen Subproblem\n",
    "\n",
    "> Column reduced cost: $\\overline{c}_p = 1 - \\sum\\limits_{v \\in V} \\pi_v . a_v$\n",
    "\n",
    "$$\n",
    "{\\large\n",
    "\\begin{array}{rll}\n",
    "\\max  &  \\sum\\limits_{v \\in V} \\pi_v . a_v &\\\\\n",
    "s.t. & & \\\\\n",
    " & a_{v} + a_{w} \\leq 1  &\\quad  d(v,w) > H + 1 \\\\\n",
    " &  a_{v} \\in \\{ 0,1 \\} & \\quad \\forall v \\in V\n",
    "\\end{array}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Variables of the Master Problem for Problem 1 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColGen Master Create lambda variables.\n",
    "\n",
    "def create_lmbda_vars(model, V):\n",
    "\n",
    "    lmbda = {}\n",
    "    n = len(V)\n",
    "    \n",
    "    for p in range(1, n + 1):\n",
    "        lmbda[p] = model.addVar(obj=1.0, vtype=GRB.CONTINUOUS, name='lamb'+'_'+str(p))\n",
    "    model.update()\n",
    "    return lmbda\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Constraints of the Master Problem for Problem 1 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColGen Master Create Set Part Constraints.\n",
    "\n",
    "def create_setpart_constraints(model, V, lmbda):\n",
    "    \n",
    "    set_part_constrs = {}\n",
    "    n = len(V)\n",
    "    \n",
    "    for v in range(1, n + 1):\n",
    "        #print(\"SETPART LAMBDA = {}\".format(lmbda[v]))\n",
    "        set_part_constrs[v] = model.addConstr(lmbda[v] == 1, name='setpart_constr_'+str(v))                                            \n",
    "    \n",
    "    model.update()\n",
    "    return set_part_constrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Variables for the Subproblem of the Problem 1 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColGen Subprob Create y_v Vars\n",
    "\n",
    "def create_a_vars(model, V):\n",
    "    \n",
    "    a = {}\n",
    "    n = len(V)\n",
    "    \n",
    "    for v in range(1, n + 1):\n",
    "        a[v] = model.addVar(obj=0.0, vtype=GRB.BINARY, name='a'+'_'+str(v))\n",
    "    model.update()\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Constraints for the Subproblem of the Problem 1 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColGen Subprob Create Conflict Constraints\n",
    "\n",
    "def create_conf_sub_constraints(model, H, V, dist, a):\n",
    "    \n",
    "    conf_constr = {}\n",
    "    n = len(V)\n",
    "    \n",
    "    for v in range(1, n):\n",
    "        for w in range(v + 1, n + 1):\n",
    "            if (((v,w) not in dist) or (dist[v,w] > H)):\n",
    "                constr_name = 'conf_constr_'+str(v)+'_'+str(w)\n",
    "                conf_constr[v, w] = model.addConstr(a[v] + a[w] <= 1, name=constr_name)                                           \n",
    "    \n",
    "    model.update()\n",
    "    return conf_constr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Creating and Solving the Subproblem (Problem 1 Column Generation)  >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub(msub, H, V, dist):\n",
    "    a = create_a_vars(msub, V)\n",
    "    conf_constrs = create_conf_sub_constraints(msub, H, V, dist, a)\n",
    "    return a, conf_constrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solvesub(msub, V, a, pi_v):\n",
    "    \n",
    "    n = len(V)\n",
    "    \n",
    "    for v in range(1, n + 1):\n",
    "        a[v].setAttr('Obj', pi_v[v])\n",
    "\n",
    "    msub.optimize()\n",
    "    zp = msub.getObjective()\n",
    "    return zp.getValue(), a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Creating and Solving the Master Problem (Problem 1 Column Generation)  >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColGen Solve Linear Relaxation\n",
    "\n",
    "def solve_ColGen_lp(V, E, vmap, graph, dist, H, timeLimit, return_clusters):\n",
    "    assert(isinstance(return_clusters, bool))\n",
    "    \n",
    "    n = len(V)\n",
    "    m = len(E)\n",
    "    pi_v = {}\n",
    "    \n",
    "    Epsilon = 0.001\n",
    "    \n",
    "    master = Model()\n",
    "    \n",
    "    print(\"\\nH (Maximum Diameter) = \", H)\n",
    "    vars_tstart = tm.time()\n",
    "    \n",
    "    # Create variable LAMBDA of the Master ColGen Problem.\n",
    "    lmbda = create_lmbda_vars(master, V)\n",
    "    #a_vp = create_a_vp_vars(master, V)\n",
    "    \n",
    "    print(\"\\nVariable LAMBDA (Master) created (execution time = {:.4f}s).\".format(tm.time() - vars_tstart))\n",
    "    \n",
    "    vars_tstart = tm.time()\n",
    "    # Create set partition constrints of the ColGen master Problem.\n",
    "    part = create_setpart_constraints(master, V, lmbda)\n",
    "    \n",
    "    print(\"\\nConstraint Set Partition (Master) created (execution time = {:.4f}s).\".format(tm.time() - vars_tstart))\n",
    "    \n",
    "    # Crete subproblem model\n",
    "    msub = Model()\n",
    "    \n",
    "    vars_tstart = tm.time()\n",
    "    a, conf_constrs = create_sub(msub, H, V, dist)\n",
    "    print(\"\\nSubproblem model created (execution time = {:.4f}s).\".format(tm.time() - vars_tstart))\n",
    "    \n",
    "    master.setParam('OutputFlag', 0)\n",
    "    msub.setParam('OutputFlag', 0)\n",
    "    \n",
    "    n_columns = n\n",
    "    not_opt = 1\n",
    "    iter_n = 0\n",
    "    total_time = 0.0\n",
    "\n",
    "    master.write(\"amm.lp\")\n",
    "    while not_opt > 0:\n",
    "\n",
    "        vars_tstart = tm.time()\n",
    "        not_opt = 0\n",
    "        master.optimize()\n",
    "\n",
    "        print ('\\nIteration #{}'.format(iter_n))\n",
    "        print ('Number of Columns = ', n_columns)\n",
    "        zd = master.getObjective()\n",
    "        print (\"Master Objective Value = {}\".format(zd.getValue()))\n",
    "\n",
    "        for v in range(1, n + 1):\n",
    "            pi_v[v] = -part[v].getAttr(\"Pi\")\n",
    "\n",
    "        redcost, a = solvesub(msub, V, a, pi_v)\n",
    "        redcost = - redcost\n",
    "        \n",
    "        #msub.write(\"sub.lp\")\n",
    "        print (\"Redcost: \", redcost)\n",
    "        #print (\"PI_V = [ {} ]\\n\".format(pi_v))\n",
    "        if redcost >= 1 + Epsilon:\n",
    "            not_opt = 1\n",
    "        \n",
    "            v_sol = msub.getAttr('X', a)\n",
    "            #print(\"a_v = \", v_sol)\n",
    "            \n",
    "            v_sol_r = [v for v in range(1,n+1) if v_sol[v] > 0.01]\n",
    "            #print(\"[ vertex such that a_v[vertex] in subproblem > 0 ] = {}\".format(v_sol_r))\n",
    "            \n",
    "            n_columns += 1\n",
    "            lmbda[n_columns] = master.addVar(obj=1.0, vtype=GRB.CONTINUOUS, name='lmbda'+'_'+str(n_columns))\n",
    "            master.update()\n",
    "            \n",
    "            for v in v_sol_r:\n",
    "                master.chgCoeff(part[v],lmbda[n_columns], 1.0)\n",
    "\n",
    "            master.update()\n",
    "            \n",
    "        else:\n",
    "            v_sol = msub.getAttr('X', a)\n",
    "            #print v_sol\n",
    "            \n",
    "            v_sol_r = [v for v in range(1,n+1) if v_sol[v] > 0.01]\n",
    "            #print(\"[ vertex such that a_v[vertex] in subproblem > 0 ] = {}\".format(v_sol_r))\n",
    "            print(\"\\nEND OF ITERATION\\n\")\n",
    "            not_opt = 0\n",
    "        \n",
    "        inc = tm.time() - vars_tstart\n",
    "        print(\"\\nTime duration = {:.4f}s.\\n\".format(inc))\n",
    "        print(\"-------------------------------------------\")\n",
    "        total_time = total_time + inc\n",
    "        iter_n = iter_n + 1\n",
    "\n",
    "    print(\"\\nAlgorithm total time duration = {:.4f}s).\".format(total_time))\n",
    "    master.write(\"mm.lp\")\n",
    "    print('Number of Columns:', n_columns)\n",
    "    \n",
    "    lmbda_sol = master.getAttr('X', lmbda)\n",
    "    #print(\"lmbda = \", lmbda_sol)\n",
    "    obj_value = 0.0\n",
    "    for ind in lmbda_sol:\n",
    "        obj_value += lmbda_sol[ind]\n",
    "    \n",
    "    print (\"Final Master Objective Value = {}\".format(obj_value))\n",
    "    zd = master.getObjective()\n",
    "    if zd.getValue():\n",
    "        print (\"Master Objective Value = {}\".format(zd.getValue()))\n",
    "        #print (\"PI_V = [ {} ]\\n\".format(pi_v))\n",
    "    \n",
    "    print(\"-------------------------------------------\\n\")\n",
    "    \n",
    "    # DEBUG PURPOSES ONLY\n",
    "    # Print constraints a_vp * lmbda_p == 1\n",
    "    #for v in range(1, n + 1):\n",
    "    #    for p in range(1, n_columns + 1):\n",
    "    #        a_vp = master.getCoeff(part[v], lmbda[p])\n",
    "    #        lmbdaX = lmbda[p].X\n",
    "    #        print(\"a_vp(v = {}, p = {}) = {} ====> {} * {} == {}\".format(v, p, a_vp, a_vp, lmbdaX, a_vp * lmbdaX))\n",
    "    #        print()\n",
    "    #print(\"\\n-------------------------------------------\\n\")\n",
    "\n",
    "    # DEBUG PURPOSES ONLY\n",
    "    # Print constraints of subproblem a_v + a_w <= 1 for all (v, w) | dist(v, w) > H FOR ALL partitions p\n",
    "    # for v in range(1, n):\n",
    "    #    for w in range(v + 1, n + 1):\n",
    "    #        if (((v,w) not in dist) or (dist[v,w] > H)):\n",
    "    #            a_v = master.getCoeff(conf_constrs[v, w], a[v])\n",
    "    #            a_w = master.getCoeff(conf_constrs[v, w], a[w])\n",
    "    #            print(\"DIST({}, {}) = {}\".format(v, w, dist[v,w]))\n",
    "    #            print(\"a_v[{}] + a_w[{}] <= 1 === {} + {} <= 1\".format(v, w, a[v].X, a[w].X))\n",
    "    # print(\"\\n------------------------------------------\\n\")\n",
    "\n",
    "    clusters = {}\n",
    "    vertex_cluster = {}\n",
    "    \n",
    "    # Mapping vertices to their respective cluster according to the optimal solution found by the mp model.\n",
    "    if(return_clusters):\n",
    "        for v in range(1, n + 1):\n",
    "            for p in range(1, n_columns + 1):\n",
    "                a_vp = master.getCoeff(part[v], lmbda[p])\n",
    "                lmbdaX = lmbda[p].X\n",
    "                if(a_vp * lmbdaX == 1.0):\n",
    "                    if p not in clusters:\n",
    "                        clusters[p] = []\n",
    "                    clusters[p].append(v)\n",
    "                    vertex_cluster[v] = p\n",
    "    \n",
    "    if zd.getValue():\n",
    "        return zd.getValue(), vertex_cluster, clusters\n",
    "    else:\n",
    "        return obj_value, vertex_cluster, clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Execution of Column Generation Algorithm for Problem 1 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Column Generation Algorithm \n",
    "# Execution of the algorithm to solve problem 1 for a given graph stored in a readable file with path file_path.\n",
    "# file_path : Path of the file containing the edges of the graph.\n",
    "# H : Maximum minimum distance between any two vertices (maximum cluster diameter)\n",
    "# enableVis : If true, plot graph with colored vertices according to the corresponding cluster.\n",
    "# return_clusters: returns a list of vertices sorted by cluster according to the found solution.\n",
    "\n",
    "def executeMinClustersGCAlgorithm(file_path, list_H, timeLimit, return_clusters, enableVis):\n",
    "\n",
    "    # Load graph from file and parse data.\n",
    "    n, m, V, E, vmap, graph, dist = loadGraphInstance(file_path)\n",
    "\n",
    "    for H in list_H:\n",
    "        # Solve the problem of minimizing the number of clusters with diameter less than or equal to H\n",
    "        opt_val, vertex_cluster, clusters = solve_ColGen_lp(V, E, vmap, graph, dist, H, timeLimit, return_clusters)\n",
    "\n",
    "        printSolution(V,opt_val, vertex_cluster, clusters)\n",
    "\n",
    "        if enableVis:\n",
    "            color_map = computeColorMap(graph, clusters, vertex_cluster)\n",
    "            \n",
    "            # FOR DEBUG PURPOSES ONLY\n",
    "            #print(\"\\nColor Map: \\n\")\n",
    "            #print(\"\\t \", color_map)\n",
    "            \n",
    "            # Visualization of the graph. Comment this line for large graphs or when visualizing the clusters is not desired.\n",
    "            if color_map != None and color_map:\n",
    "                visualizeGraph(graph, layout_attr='random', color_map=color_map, scale=1000, enable_edges=True, node_size=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Execute the cell below to use the Column Generation Algorithm for Problem 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to use the algorithm and find optimal solutions for the formulation using Column Generation.\n",
    "\n",
    "file_path = \"instances/as19990829.txt\"\n",
    "timeLimit = 60*60*4\n",
    "\n",
    "# file_path = \"instances/as19981229.txt\"\n",
    "# timeLimit = 60*60*6\n",
    "\n",
    "# file_path = \"instances/as19981230.txt\"\n",
    "# timeLimit = 60*60*6\n",
    "\n",
    "\n",
    "# Maximum minimum distance between any two vertices (maximum cluster diameter)\n",
    "list_H = [1, 2, 3, 5, 6]\n",
    "\n",
    "enableVis = False\n",
    "\n",
    "return_clusters = True\n",
    "\n",
    "executeMinClustersGCAlgorithm(file_path, list_H, timeLimit, return_clusters , enableVis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
