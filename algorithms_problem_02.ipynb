{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Solver for Problem 2 (Maximum Connectivity Clustering Model - G=(V,E))\n",
    "\n",
    "### Ítalo Gomes Santana, Rafael Azevedo e Rodrigo Laigner\n",
    "\n",
    "### Pontifical Catholic University of Rio de Janeiro (PUC-RIO) 2018.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: ramscrz, rodrigo, italo\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import time as tm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from gurobipy import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Loading and Initialization of the Input Graph for Problem 1 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Instance\n",
    "def read_graph(file_name):\n",
    "    \n",
    "    print(\"\\nLoading instance from file: \", file_name)\n",
    "    f = open(file_name,'r+')\n",
    "    \n",
    "    vmap = {}\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        \n",
    "        # Ignore comment lines and blocks in the file.\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "\n",
    "        # Read a line containing two integers, representing the two vertices of an edge.\n",
    "        item_data = line.split()\n",
    "        if len(item_data) != 2:\n",
    "            # Invalid line data: \n",
    "            continue\n",
    "\n",
    "        # Get the first vertex of the edge\n",
    "        i = int(item_data[0])\n",
    "        # Get the second vertex of the edge\n",
    "        j = int(item_data[1])\n",
    "\n",
    "        # Map each read vertex to a position of the vmap array, setting a unique integer to each vertex.\n",
    "        if i not in vmap:\n",
    "            vmap[i] = len(vmap) + 1\n",
    "        if j not in vmap:\n",
    "            vmap[j] = len(vmap) + 1\n",
    "\n",
    "        # Set the source vertex index of the edge as the one mapped to the minimum integer.\n",
    "        # Set the sink vertex index of the edge as the one mapped to the maximum integer.\n",
    "        source = min(vmap[i], vmap[j])\n",
    "        sink   = max(vmap[i], vmap[j])\n",
    "        \n",
    "        # Compute edges ignoring loops because distance is 0.\n",
    "        # Edges weights are set as 1 by default.\n",
    "        if source != sink and (source,sink) not in graph.edges(): \n",
    "            graph.add_edge(source, sink, weight=1)\n",
    "\n",
    "    #print(vmap)\n",
    "    f.close()\n",
    "    \n",
    "    V = { index:vertex for vertex,index in vmap.items() }\n",
    "    \n",
    "    print(\"N vértices: \", len(V))\n",
    "    print(\"M edges: \", len(graph.edges()))\n",
    "    \n",
    "    # FOR DEBUG PURPOSES ONLY.\n",
    "    #print(\"\\nVertices: \\n {}\\n\".format(graph.nodes()))\n",
    "    #print(\"\\nEdges: \\n {}\\n\".format(graph.edges()))\n",
    "    #print(\"\\nEdges with weights: \\n {}\\n\".format(graph.edges(data='weight')))\n",
    "    #print(vmap.keys())\n",
    "    \n",
    "    return len(V), len(graph.edges()), vmap, graph, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(V,E):\n",
    "    n = len(V)\n",
    "    adjs = {}\n",
    "    \n",
    "    for v in V:\n",
    "        adjs[v] = []\n",
    "    \n",
    "    # Compute the edge adjacency list for each vertex.\n",
    "    for e in E:\n",
    "        adjs[e[0]].append(e[1])\n",
    "        adjs[e[1]].append(e[0])\n",
    "\n",
    "    n = len(V)\n",
    "    dist = {}\n",
    "\n",
    "    # BFS to compute the minimum distance between each edge (v, s) for all vertices v, s of V. \n",
    "    for v in V:\n",
    "        L=[v]\n",
    "        dist[v,v]=0\n",
    "        # While the frontier is not empty, continue BFS.\n",
    "        while( len(L) > 0 ):\n",
    "            c = L[0]\n",
    "            L.remove(c)\n",
    "            for s in adjs[c]:\n",
    "                if ( (v,s) not in dist ):\n",
    "                    dist[v,s] = dist[v,c] + 1\n",
    "                    L.append(s)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically a reverse map of vertices of an edge.\n",
    "def getEdgeMapping(source, sink, vmap):\n",
    "    return (vmap[source],vmap[sink])\n",
    "\n",
    "# Get the edge vertices integer indexed by a unique integer.\n",
    "# Basically a reverse map of vertices of an edge for every edge in E.\n",
    "def remap_edges(E,V):\n",
    "    return  [ (V[i],V[j]) for i,j in E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeGraph(graph, layout_attr='circular', color_map=None, scale=10, enable_edges=True, node_size=30):\n",
    "    \n",
    "    layout = None\n",
    "    \n",
    "    if(layout_attr==\"bipartite\"):\n",
    "        # Position nodes in two straight lines.\n",
    "        print(\"\\nBipartite Graph: \")\n",
    "        layout = nx.bipartite_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"circular\"):\n",
    "        # Position nodes on a circle.\n",
    "        print(\"\\Circular Graph: \")\n",
    "        layout = nx.circular_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"kamada_kawai\"):\n",
    "        # Position nodes using Kamada-Kawai path-length cost-function.\n",
    "        print(\"\\Kamada-kawai Graph: \")\n",
    "        layout = nx.kamada_kawai_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"random\"):\n",
    "        # Position nodes uniformly at random in the unit square.\n",
    "        print(\"\\Random Graph: \")\n",
    "        layout = nx.random_layout(graph)\n",
    "    elif(layout_attr==\"rescale\"):\n",
    "        # Return scaled position array to (-scale, scale) in all axes.\n",
    "        print(\"\\Rescale Graph: \")\n",
    "        layout = nx.rescale_layout(graph)\n",
    "    elif(layout_attr==\"shell\"):\n",
    "        # Position nodes in concentric circles.\n",
    "        print(\"\\Shell Graph: \")\n",
    "        layout = nx.shell_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"spring\"):\n",
    "        #Position nodes using Fruchterman-Reingold force-directed algorithm.\n",
    "        print(\"\\Spring Graph: \")\n",
    "        layout = nx.spring_layout(graph, scale=scale)\n",
    "    elif(layout_attr==\"spectral\"):\n",
    "        # Position nodes using the eigenvectors of the graph Laplacian.\n",
    "        print(\"\\nSpectral Graph: \")\n",
    "        layout = nx.spectral_layout(graph, scale=scale)\n",
    "    else:\n",
    "        layout = nx.random_layout(graph, scale=scale)\n",
    "    \n",
    "    nx.draw_networkx_nodes(graph, layout)\n",
    "    \n",
    "    edge_labels = dict([((u,v,),d[ 'weight']) for u,v,d in graph.edges(data=True)])\n",
    "    \n",
    "    #nx.draw_networkx_labels(graph, layout, font_size=20, font_family='sans-serif')\n",
    "    if(enable_edges):\n",
    "        nx.draw_networkx_edges(graph, layout)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.figure(3,figsize=(12,12))\n",
    "    \n",
    "    #nx.draw_networkx_edge_labels(graph, layout, edge_labels=edge_labels)\n",
    "    \n",
    "    if color_map != None:\n",
    "        nx.draw(graph, layout, edge_cmap=plt.cm.Reds, node_size=node_size,font_size=8, node_color=color_map)\n",
    "    else:\n",
    "        nx.draw(graph, layout, edge_cmap=plt.cm.Reds, node_size=node_size,font_size=8)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGraphInstance(file_name):\n",
    "    n, m, vmap, graph, V = read_graph(file_name)\n",
    "    dist = compute_distances(list(V.keys()), graph.edges())\n",
    "    \n",
    "    # FOR DEBUG PURPOSES ONLY.\n",
    "    #print(\"VERTICES:\\n\")\n",
    "    #print(V)\n",
    "    #print(\"VMAP:\\n\")\n",
    "    #print(vmap)\n",
    "    #print(\"EDGES:\\n\")\n",
    "    #print(graph.edges())\n",
    "\n",
    "    E = remap_edges(graph.edges(), V)\n",
    "\n",
    "    # FOR DEBUG PURPOSES ONLY\n",
    "    #print(\"REVERSE MAPPED EDGES:\\n\")\n",
    "    #print(E)\n",
    "    #print(\"MINIMUM DISTANCE BETWEEN VERTICES:\\n\")\n",
    "    #print(dist)\n",
    "    \n",
    "    return n, m, V, E, vmap, graph, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ######################################### FOR DEBUG PURPOSES ONLY #################################################\n",
    "\n",
    "# n, m, V, E, vmap, graph, dist = loadGraphInstance(\"tvshow_edges_shorter.txt\")\n",
    "\n",
    "# print(\"\\nEncoded N: \", n, \"- Vertices:\", graph.nodes())\n",
    "# print(\"\\nEncoded M: \", m, \"- Edges:\", graph.edges())\n",
    "\n",
    "# print(\"\\nN:\", n, \"- V:\", V)\n",
    "# print(\"\\nM:\", m, \"- E:\", E)\n",
    "\n",
    "# scale = 1000\n",
    "# en_edges = False\n",
    "\n",
    "# print(\"\\nCircular Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='circular', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nKamada Kawai Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='kamada_kawai', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nRandom Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='random', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nShell Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='shell', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nSpring Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='spring', scale=scale, enable_edges=en_edges)\n",
    "# print(\"\\nSpectral Layout: \")\n",
    "# visualizeGraph(graph, layout_attr='spectral', scale=scale, enable_edges=en_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulação para o Problema 2 (Clique Clustering Model - G=(V,E))\n",
    "## Clique Clustering Model - G=(V,E) - Fix # Clusters - Max conectividade\n",
    "\n",
    "$$\n",
    "{\\large\n",
    "\\begin{array}{rll}\n",
    "\\min  &  \\rho  &\\\\\n",
    "s.t. & & \\\\\n",
    " & d(v,w).\\delta_{vwk} \\leq \\rho & \\quad \\forall (v,w) \\in V \\times V \\quad k = 1,\\ldots,n\\\\\n",
    " & \\delta_{vwk}\\ =\\ (y_{vk} * y_{wk})\\ &\\quad \\forall (v,w) \\in V \\times V \\quad k = 1,\\ldots,n\\\\\n",
    " & y_{vk}\\ \\leq\\ z_k & \\quad \\forall v \\in V \\quad \\forall k= 1,\\ldots, n \\> = \\> |V| \\\\\n",
    " & \\sum\\limits_{k=1}^{n} y_{vk} = 1 & \\quad \\forall v \\in V \\\\\n",
    " &  \\sum\\limits_{k=1}^{n} z_k \\leq \\ell &\\\\\n",
    " &  y_{vk} \\in \\{ 0,1 \\} &\\quad \\forall (v,k) \\in V \\times V\\ where\\ k = 1,\\ldots,n & \\\\\n",
    " &  z_{k} \\in \\{ 0,1 \\} &\\quad k = 1,\\ldots,n & \\\\\n",
    " &  \\delta_{vw} \\in \\{ 0,1 \\} &\\quad \\forall (v,w) \\in V \\times V & \\\\\n",
    "\\end{array}\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Variables for Problem 2 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create y_vk variables which represent the belonging of vertex v to the cluster k.\n",
    "# If vertex v belongs to cluster k, then y_vk == 1. Otherwise, y_vk == 0.\n",
    "# Binary decision variable.\n",
    "\n",
    "def create_yvk_vars(model, V):\n",
    "    n = len(V)\n",
    "    \n",
    "    y_vk = {}\n",
    "    \n",
    "    # For each vertex v and cluster k, vertex v belongs to cluster k (y_vk == 1) or not (y_vk == 0).\n",
    "    for k in range(1, n+1):\n",
    "        for v in range(1, n+1):\n",
    "            y_vk[v, k] = model.addVar(obj=0.0, vtype=GRB.BINARY, name='y_vk'+'_'+str(v)+str(k))\n",
    "    model.update()\n",
    "    return y_vk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create z_k variables which represent the inclusion of cluster k to the set of clusters composing the solution.\n",
    "# If cluster k belongs to the set of disjoint partitions of V, then z_k == 1. Otherwise, z_k == 0.\n",
    "# If z_k == 0, then no vertex is allocated to the cluster k and cluster k is excluded from the solution.\n",
    "\n",
    "def create_zk_vars(model, V):\n",
    "\n",
    "    z_k = {}\n",
    "    \n",
    "    for k in range(1, len(V) + 1):\n",
    "        z_k[k] = model.addVar(obj=0.0, vtype=GRB.BINARY, name='z'+'_'+str(k))\n",
    "    model.update()\n",
    "    return z_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create delta_vwk binary variables which activates the diameter constraints dist(v, w) * d_vwk <= rho, where rho\n",
    "# represents the maximum allowed diameter of a cluster and dist(v, w) the minimum distance between vertices v and w.\n",
    "#\n",
    "# Therefore:\n",
    "#    1. if delta_vwk is 1, then vertices v and w belong to the same cluster, then dist(v, w) must be less or equal \n",
    "#       to rho.\n",
    "#    2. if delta_vwk is 0, then vertices v and w don't belong to the same cluster, then dist(v, w) is multiplied by \n",
    "#       0 and this constraint doesn't regulate the dist(v, w).\n",
    "#\n",
    "# delta_vwk represents the status of belonging of vertices v and w to the cluster k. \n",
    "\n",
    "def create_d_vwk_vars(model, V, dist):\n",
    "\n",
    "    n = len(V)\n",
    "    d_vwk = {}\n",
    "    \n",
    "    for k in range(1, n + 1):\n",
    "        for v in range(1, n):\n",
    "            for w in range(v+1, n+1):\n",
    "                if((v, w) in dist):\n",
    "                    d_vwk[v, w, k] = model.addVar(obj=0.0, vtype=GRB.BINARY, name='delta_'+str(v)+\"_\"+str(w)+\"_\"+str(k))\n",
    "    model.update()\n",
    "    return d_vwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create rho variable which represent the maximum diameter allowed for any cluster. This diameter must be minimized.\n",
    "\n",
    "def create_h_var(model, V):\n",
    "\n",
    "    h = model.addVar(obj=1.0, vtype=GRB.INTEGER, name='rho_h')\n",
    "    \n",
    "    model.update()\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Constraints for Problem 2 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diameter-limit constraints which restricts a pair of vertices (v, w) to belong to the same cluster k\n",
    "# only if the minimum distance between these vertices is at most h (variable rho), the objective function variable.\n",
    "# If the minimum distance between vertices v and w is greater than h (rho), then v or w belongs to cluster k\n",
    "# or v, w not in cluster k.\n",
    "\n",
    "def create_conf_vwk_constraints(model, y_vk, d_vwk, V, h, dist):\n",
    "\n",
    "    n = len(V)\n",
    "    total = 0\n",
    "    print(n)\n",
    "    conf_constrs = {}\n",
    "    dist_h_constrs = {}\n",
    "    y_vwk = {}\n",
    "    print(\"create_conf_vwk_constraints\")\n",
    "    for k in range(1, n+1):\n",
    "        for v in range(1, n):\n",
    "            for w in range(v+1, n+1):\n",
    "                total = total + 1\n",
    "                if( (v, w, k) in d_vwk ):\n",
    "                    total = total + 1\n",
    "                    constr_name = 'conf_constr_'+str(v)+'_'+str(w)+'_'+str(k)\n",
    "                    conf_constrs[v, w, k] = model.addConstr(d_vwk[v, w, k] == (y_vk[v, k] * y_vk[w, k]), name=constr_name)\n",
    "                    constr_name = 'limit_distance_constr_'+str(v)+'_'+str(w)+'_'+str(k)\n",
    "                    dist_h_constrs[v, w, k] = model.addConstr(dist[v, w] * d_vwk[v, w, k] <= h, name=constr_name)                    \n",
    "                else:\n",
    "                    constr_name_01 = 'conf_constr_else_'+str(v)+'_'+str(w)+'_'+str(k)\n",
    "                    conf_constrs[v, w, k] = model.addConstr(y_vk[v, k] + y_vk[w, k] <= 1, name=constr_name_01)\n",
    "\n",
    "    model.update()\n",
    "    print(\"Total conflict constraints created = \", total)\n",
    "    return conf_constrs, dist_h_constrs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create upper bound constraints which assures that z_k will be assigned value 0 if a cluster holds no vertex.\n",
    "# If there are more than 0 vertices in cluster k, then z_k might assume values 0 or 1 according to this constraint.\n",
    "# However z_k must be 1 if exists more at least one vertex in cluster k. For this reason, the asgn_constraint is\n",
    "# created in the next cells.\n",
    "\n",
    "def create_up_constraints(model, y_vk, z_k, V):\n",
    "    n = len(V)\n",
    "    total = 0\n",
    "    up_constrs = {}\n",
    "\n",
    "    print(\"create_up_constraints\")\n",
    "    \n",
    "    for k in range(1, n + 1):\n",
    "        for v in range(1, n + 1):\n",
    "            total = total + 1\n",
    "            up_constrs[v,k] = model.addConstr(z_k[k] >= y_vk[v, k], name='up_constr_'+str(v)+'_'+str(k))\n",
    "    \n",
    "    model.update()\n",
    "    print(\"Total up constraints created = \", total)\n",
    "    return up_constrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Assignment constraints which restricts a vertex to belong only to one cluster at a time.\n",
    "# Each vertex belongs to one and one only cluster because partitions must be disjoint subsets of vertices.\n",
    "# If exist a vertex v that belongs to cluster k, then z_k must be assigned value 1. \n",
    "# Otherwise, z_k must be assigned 0. This is assured by the quicksum of the product y_vk[v, k] * z_k[k].\n",
    "    \n",
    "def create_asgn_constraints(model, y_vk, V):\n",
    "    n = len(V)\n",
    "    total = 0\n",
    "    asgn_constrs = {}\n",
    "    \n",
    "    for v in range(1, n + 1):\n",
    "        total = total + 1\n",
    "        constr_name = 'asgn_constr'+str(v)\n",
    "        asgn_constrs[v] = model.addConstr((quicksum(y_vk[v, k] for k in range(1, n + 1)) == 1), name=constr_name)\n",
    "    \n",
    "    model.update()\n",
    "    print(\"\\nTotal assignment constraints created = \", total)\n",
    "    return asgn_constrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create number of custers limit constraints which assures that there are only at most l clusters k (z_k == 1).\n",
    "# If z_k == 1, then cluster k exists in the solution. Otherwise, cluster k does not exist in the solution.\n",
    "# l is a given parameter.\n",
    "\n",
    "def create_nclusters_limit_constraints(model, z_k, V, l, en_exact_nc=False):\n",
    "    \n",
    "    n = len(V)\n",
    "    nclusters_limit_constrs = None\n",
    "    constr_name = 'nclusters_limit_constr'\n",
    "    \n",
    "    if en_exact_nc:\n",
    "        nclusters_limit_constrs = model.addConstr((quicksum(z_k[k] for k in range(1, n + 1)) == l), name=constr_name)\n",
    "    else:\n",
    "        nclusters_limit_constrs = model.addConstr((quicksum(z_k[k] for k in range(1, n + 1)) <= l), name=constr_name)\n",
    "    \n",
    "    model.update()\n",
    "    print(\"\\nTotal number clusters limit constraints created = 1\")\n",
    "    return nclusters_limit_constrs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create objective function.\n",
    "\n",
    "def setObjective(model, h):\n",
    "    model.setObjective(h, GRB.MINIMIZE)\n",
    "    model.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Primal-Dual Solver for Problem 2 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l => Maximum number of clusters\n",
    "def solveMaxConnClusters(V, E, vmap, graph, dist, l, timeLimit, en_exact_nc=False):\n",
    "     \n",
    "    n = len(V)\n",
    "    m = len(E)\n",
    "    \n",
    "    mp = Model()\n",
    "    \n",
    "    # Binary variables \n",
    "    y_vk = {}\n",
    "    y_vwk = {}\n",
    "    z_k = {}\n",
    "    d_vw = {}\n",
    "    d_vwk = {}\n",
    "    \n",
    "    \n",
    "    # Constraints\n",
    "    conf_constrs = {}\n",
    "    dist_h_constrs = {}\n",
    "    up_constrs = {}\n",
    "    asgn_constrs = {}\n",
    "    nclusters_limit_constrs = {}\n",
    "    \n",
    "    print(\"l (Maximum Number of Clusters) = \", l)\n",
    "    \n",
    "    vars_tstart = tm.time()\n",
    "    \n",
    "    print(\"Creating variables\")\n",
    "    \n",
    "    # Create variables y_vk for each vertex v and cluster k\n",
    "    # y_vk == 1 => vertex v belongs to cluster k\n",
    "    # y_vk == 0 => vertex v does not belong to cluster k\n",
    "    y_vk = create_yvk_vars(mp, V)\n",
    "    \n",
    "    print(\"yvk created\")\n",
    "    \n",
    "    # Create variables z_k for each disjoint cluster k\n",
    "    # z_k = 1 => cluster k exists.\n",
    "    # z_k = 0 => cluster k does not exist.\n",
    "    z_k = create_zk_vars(mp, V)\n",
    "    \n",
    "    print(\"zk created\")\n",
    "    \n",
    "    # Create variables d_vw for each existing edge (v, w)\n",
    "    # d_vw = 1 => dist(v, w) <= h (rho)\n",
    "    # d_vw = 0 => dist(v, w) > h (rho).\n",
    "    d_vwk = create_d_vwk_vars(mp, V, dist)\n",
    "    \n",
    "    print(\"d vwk created\")\n",
    "    \n",
    "    # Create objective variable h which represents the minimum diameter of clusters for having l clusters\n",
    "    h = create_h_var(mp, V)\n",
    "    \n",
    "    vars_exec_time = tm.time() - vars_tstart\n",
    "    print(\"Variables created (execution time = {:.4f}s).\".format(vars_exec_time))\n",
    "    print(\"Creating constraints\")\n",
    "    \n",
    "    constrs_tstart = tm.time()\n",
    "    \n",
    "    # Create constraint for avoiding conflict (vertices farther than H + 1 belong to different cluster).\n",
    "    conf_constrs, dist_h_constrs = create_conf_vwk_constraints(mp, y_vk, d_vwk, V, h, dist)\n",
    "    \n",
    "    print(\"conf vwk created\")\n",
    "    \n",
    "    # Create upper bound constraints (y_vk <= z_k)\n",
    "    up_constrs = create_up_constraints(mp, y_vk, z_k, V)\n",
    "    \n",
    "    print(\"up created\")\n",
    "    \n",
    "    # Create assignment constraint (each vertex belongs to one and one only cluster)\n",
    "    asgn_constrs = create_asgn_constraints(mp, y_vk, V)\n",
    "    \n",
    "    print(\"asgn created\")\n",
    "    \n",
    "    # Create number of clusters limit constraint (there can't be more than l clusters)\n",
    "    nclusters_limit_constrs = create_nclusters_limit_constraints(mp, z_k, V, l, en_exact_nc)\n",
    "    \n",
    "    print(\"nclusters created\")\n",
    "    \n",
    "    setObjective(mp, h)\n",
    "    print(\"setobj\")\n",
    "    constrs_exec_time = tm.time() - constrs_tstart\n",
    "    print(\"Constraints created (execution time = {:.4f}s).\\n\".format(constrs_exec_time))\n",
    "    \n",
    "    # Time limit for searching an optimal solution.\n",
    "\n",
    "    print(\"TimeLimit: {}\\n\".format(timeLimit))\n",
    "    \n",
    "    mp.write(\"mf_clust.lp\")\n",
    "    mp.setParam('TimeLimit', timeLimit)\n",
    "    mp.setParam('OutputFlag', 1)\n",
    "    \n",
    "    print()\n",
    "    print(\"\\n####### SOLVER START #######\\n\")\n",
    "    solver_tstart = tm.time()\n",
    "    mp.optimize()\n",
    "    solver_exec_time = tm.time() - solver_tstart\n",
    "    print(\"\\nSolver finished (execution time = {:.4f}s)\\n\".format(solver_exec_time))\n",
    "    print(\"\\n####### SOLVER END #######\\n\")\n",
    "    print()\n",
    "    \n",
    "    zp = mp.getObjective()\n",
    "\n",
    "    \n",
    "    if(mp.getAttr(GRB.Attr.ModelSense) == 1):\n",
    "        print(\"Minimization\")\n",
    "    else:\n",
    "        print(\"Maximization\")\n",
    "    print(\"Objective function: {}\".format(zp.getValue()))\n",
    "    print(\"TOTAL EXECUTION TIME = {:.4f}s\\n\".format(vars_exec_time + constrs_exec_time + solver_exec_time))\n",
    "    \n",
    "    #v_sol = mp.getAttr('X', y_vk)\n",
    "    #print v_sol\n",
    "    \n",
    "    # Retrieve for each vertex the respective cluster to which it belongs to.\n",
    "    #v_sol_r = {v:k for v in range(1, n + 1) for k in range(1, n + 1) if v_sol[v,k] > 0.001}\n",
    "    \n",
    "    #clusters = {}\n",
    "        \n",
    "    #for v,k in v_sol_r.items():\n",
    "    #    if k not in clusters.keys():\n",
    "    #        clusters[k] = []\n",
    "    #    clusters[k].append(v)\n",
    "    \n",
    "    mp.write(\"mp.lp\")\n",
    "    dvw_sol = mp.getAttr('X', d_vwk)\n",
    "    yvk_sol = mp.getAttr('X', y_vk)\n",
    "    zk_sol = mp.getAttr('X', z_k)\n",
    "    yvk = {v:k for v in range(1, n + 1) for k in range(1, n + 1) if yvk_sol[v,k] > 0.001}\n",
    "    #print(zk_sol)\n",
    "    #print(yvk)\n",
    "    #print(yvk_sol)\n",
    "    #print(dvw_sol)\n",
    "    \n",
    "    clusters = {}\n",
    "    \n",
    "    for v, w, k in dvw_sol.keys():\n",
    "        if( dvw_sol[v, w, k] == 1 ):\n",
    "            yvk_c = yvk[v]\n",
    "            ywk_c = yvk[w]\n",
    "            #print(\"d_vwk( v: {}, w: {}, k: {} ) = {}\".format(v, w, k, dvw_sol[v, w, k]))\n",
    "            #print(\"DISTANCE [ v: {}, w: {} ] = {}\".format(v, w, dist[v, w]))\n",
    "            if yvk_c not in clusters.keys():\n",
    "                clusters[yvk_c] = []\n",
    "            if v not in clusters[yvk_c]:\n",
    "                clusters[yvk_c].append(v)\n",
    "            if ywk_c not in clusters.keys():\n",
    "                clusters[ywk_c] = []\n",
    "            if w not in clusters[ywk_c]:\n",
    "                clusters[ywk_c].append(w)\n",
    "            if yvk_c != ywk_c:\n",
    "                print(\"ERROR: d_vwk( v: {}, w: {}, k: {} ) == 1 but v in cluster {} and w in cluster {}\".format(v, w, k, yvk_c, ywk_c))\n",
    "    \n",
    "    #for k in clusters.keys():\n",
    "    #    print(\"Cluster #\", k)\n",
    "    #    print(\"\\t{}\".format(clusters[k]))\n",
    "    \n",
    "    return zp.getValue(), yvk, clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Output of Results for Problem 2 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of color shades for each cluster and set the corresponding cluster color to each vertex.\n",
    "\n",
    "def computeColorMap(graph, clusters, vertex_cluster):\n",
    "    assert(isinstance(clusters, dict))\n",
    "    assert(isinstance(vertex_cluster, dict))\n",
    "    \n",
    "    if(not clusters or not vertex_cluster):\n",
    "        return None\n",
    "    \n",
    "    color_map = []\n",
    "    \n",
    "    cmap = cm.autumn\n",
    "    norm = Normalize(vmin=0,vmax=1)\n",
    "\n",
    "    ratio = 1.0 / len(clusters)\n",
    "    k_index = {}\n",
    "    k_counter = 1\n",
    "    for node in graph:\n",
    "        k = vertex_cluster[node]\n",
    "        #print(\"\\tNode: {} => k = {}\".format(node, k))\n",
    "        if k not in k_index.keys():\n",
    "            k_index[k] = k_counter\n",
    "            k_counter += 1\n",
    "        color_map.append(cmap(norm(k_index[k] * ratio)))\n",
    "    \n",
    "    return color_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSolution(zp, vertex_cluster, clusters, V, log_file_name=None):\n",
    "    assert(isinstance(vertex_cluster, dict))\n",
    "    assert(isinstance(clusters, dict))\n",
    "    \n",
    "    text_file = None\n",
    "    \n",
    "    if(isinstance(log_file_name, str)):\n",
    "        text_file = open(log_file_name, \"a\")\n",
    "        text_file.write(\"\\nMinimum Maximum Distance in Clusters: {}\\n\".format(zp))\n",
    "    print (\"\\nMinimum Maximum Distance in Clusters: \", zp)\n",
    "    \n",
    "    if(vertex_cluster != None and vertex_cluster):\n",
    "        print (\"\\nSolution (vertex_index, k_cluster_index): \\n\\n\\t{}\\n\".format(vertex_cluster))\n",
    "        if(text_file != None):\n",
    "            text_file.write(\"\\nSolution (vertex_index, k_cluster_index): \\n\\n\\t{}\\n\".format(vertex_cluster))\n",
    "    \n",
    "    if(isinstance(log_file_name, str)):\n",
    "        text_file = open(log_file_name, \"a\")\n",
    "        text_file.write(\"\\n\\n====> Clusters:\\n\\n\")\n",
    "    if(clusters != None and clusters):\n",
    "        for k,vertices in clusters.items():\n",
    "            print(\"\\tCluster #{} contains the following vertices: \\n\".format(k))\n",
    "            if(text_file != None):\n",
    "                text_file.write(\"\\tCluster #{} contains the following vertices: \\n\".format(k))\n",
    "            line_buffer = 0\n",
    "            for v in vertices:\n",
    "                if(line_buffer == 0):\n",
    "                    print(\"\\t\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]), end = '')\n",
    "                    if(text_file != None):\n",
    "                        text_file.write(\"\\t\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]))\n",
    "                else:\n",
    "                    print(\"\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]), end = '')\n",
    "                    if(text_file != None):\n",
    "                        text_file.write(\"\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]))\n",
    "                line_buffer += 1\n",
    "                \n",
    "                # Blank line paragraph after printing 3 vertices.\n",
    "                if(line_buffer == 3):\n",
    "                    print()\n",
    "                    if(text_file != None):\n",
    "                        text_file.write(\"\\n\")\n",
    "                    line_buffer = 0\n",
    "            print(\"\\n\")\n",
    "            if(text_file != None):\n",
    "                text_file.write(\"\\n\")\n",
    "    \n",
    "    if(text_file != None):\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Execution of Primal-Dual Algorithm for Problem 2 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def solveProbClusterMaxConnect(file_path, list_L, en_exact_nc=False, timeLimit=5000, show_graph=False, log_file_name=None):\n",
    "    \n",
    "    ###################################\n",
    "    # file_path = \"t01.txt\"\n",
    "    ###################################\n",
    "    \n",
    "    ###################################\n",
    "    # Maximum number of clusters\n",
    "    # list_L = [2, 1, 3]\n",
    "    ###################################\n",
    "    \n",
    "    ###################################\n",
    "    # If True, solves to find exactly l clusters. Otherwise, solves for any number of clusters less than l.\n",
    "    # en_exact_nc = False\n",
    "    ###################################\n",
    "\n",
    "    ###################################\n",
    "    # timeLimit = 60*60*4\n",
    "    ###################################\n",
    "    \n",
    "    n, m, V, E, vmap, graph, dist = loadGraphInstance(file_path)\n",
    "    \n",
    "    print(\"\\n\\nInput file: {}\\n\".format(file_path))\n",
    "    \n",
    "    # Iterate over all maximum number of clusters provided. The problem is separately solved for each l.\n",
    "    for l in list_L:\n",
    "        \n",
    "        print(\"\\n=====================================================================\\n\")\n",
    "        print(\"++++++++++++++++++++++++ ITERATION FOR L = {} ++++++++++++++++++++++++\".format(l))\n",
    "        print(\"\\n=====================================================================\\n\")\n",
    "        print(\"l = \", l)\n",
    "        \n",
    "        opt_val = None\n",
    "        vertex_cluster = {}\n",
    "        clusters = {}\n",
    "\n",
    "        # Solve the problem of minimizing the diameter in clusters given a maximum number of cluster equal to l.\n",
    "        opt_val, vertex_cluster, clusters = solveMaxConnClusters(V, E, vmap, graph, dist, l, timeLimit, en_exact_nc)\n",
    "    \n",
    "        if(opt_val != None):\n",
    "            print(\"Opt MIN maximum distance between vertices in clusters = \", opt_val)\n",
    "    \n",
    "        ###################################\n",
    "        #for v, w in dist:\n",
    "            #print(\"DISTANCE [ v: {}, w: {} ] = {}\".format(v, w, dist[v, w]))\n",
    "        ###################################\n",
    "    \n",
    "        log_file_n = None\n",
    "        log_file = None\n",
    "        randomUID = None\n",
    "        \n",
    "        # Writes the header of the LOG FILE if a log file name has been provided.\n",
    "        if(isinstance(log_file_name, str)):\n",
    "            randomUID = ''.join(random.choice(string.ascii_lowercase) for i in range(10))\n",
    "            log_file_n = log_file_name + \"_l=\" + str(l) + \"_\" + randomUID + \".txt\"\n",
    "            print(\"\\nLOG FILE: {}\\n\".format(log_file_n))\n",
    "            log_file = open(log_file_n, \"a\")\n",
    "            log_file.write(\"\\n=====> LOG FILE FOR PROBLEM 02 MAX CONNECTIVITY CLUSTERING\\n\")\n",
    "            log_file.write(\"\\n\\nInput file: {}\\n\".format(file_path))\n",
    "            log_file.write(\"\\nITERATION FOR L = {} \\n\".format(l))\n",
    "            log_file.close()\n",
    "            log_file = None\n",
    "        \n",
    "        # Prints the found solution (also writes the solution to the log file if provided).\n",
    "        if(opt_val!=None and vertex_cluster!=None and clusters!=None):\n",
    "            if(log_file_n != None):\n",
    "                printSolution(opt_val, vertex_cluster, clusters, V, log_file_n)\n",
    "            else:\n",
    "                printSolution(opt_val, vertex_cluster, clusters, V)\n",
    "\n",
    "            if show_graph:\n",
    "                color_map = computeColorMap(graph, clusters, vertex_cluster)\n",
    "\n",
    "                #print(\"\\nColor Map: \\n\")\n",
    "                #print(\"\\t \", color_map)\n",
    "\n",
    "                visualizeGraph(graph, layout_attr='random', color_map=color_map, scale=1000, enable_edges=True, node_size=50)\n",
    "        else:\n",
    "            if(isinstance(log_file_name, str)):\n",
    "                log_file_n = log_file_name + \"_l=\" + str(l) + \"_\" + randomUID + \".txt\"\n",
    "                log_file = open(log_file_n, \"a\")\n",
    "                log_file.write(\"Model is NOT FEASIBLE or NOT OPTIMAL.\\n\\n\")\n",
    "                log_file.close()\n",
    "                log_file = None\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Execute the cell below to use the Primal-Dual algorithm for Problem 2 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Execute this cell to use the algorithm and find optimal solutions for the formulation above.\n",
    "\n",
    "# Path of the file containing the edges of the graph.\n",
    "file_paths = [\"instances/as19990829.txt\",\"instances/as19981229.txt\",\"instances/as19990829.txt\"]\n",
    "\n",
    "\n",
    "# Path of the file containing the log of the algorithm (results). If NONE, then no log file is generated.\n",
    "#log_file_path = \"log_file_problem02\"\n",
    "log_file_path = None\n",
    "# Maximum number of clusters having the minimum maximum diameter possible.\n",
    "L = [2, 16, 67]\n",
    "\n",
    "timeLimit = 60*60*6\n",
    "\n",
    "# Set the number of clusters to be exact if True. Otherwise, the number of cluster must be equal or less than l.\n",
    "en_exact_nc = True\n",
    "\n",
    "# Solve for each input file path in file_paths.\n",
    "# for file_path in file_paths:\n",
    "#     solveProbClusterMaxConnect(file_path=file_path, list_L=L, en_exact_nc=en_exact_nc, timeLimit=timeLimit,\n",
    "#                                show_graph=True, log_file_name=log_file_path)\n",
    " \n",
    "\n",
    "\n",
    "# Solve for each input file path in file_paths.\n",
    "for file_path in file_paths:\n",
    "    solveProbClusterMaxConnect(file_path=file_path, list_L=L, en_exact_nc=en_exact_nc, timeLimit=timeLimit,\n",
    "                               show_graph=True, log_file_name=log_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver for Connectivity Maximization Problem (02) using Column Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColGen Formulation - Master Problem\n",
    "\n",
    "$$\n",
    "{\\large\n",
    "\\begin{array}{rll}\n",
    "\\min  &  \\sum\\limits_{p \\in \\cal{P}} \\lambda_p &\\\\\n",
    "s.t. & & \\\\\n",
    "(\\mbox{Dual } \\pi_v) & \\sum\\limits_{p \\in \\cal{P}} a_{vp} . \\lambda_p = 1 & \\quad \\forall v \\in V \\\\\n",
    "(\\mbox{Dual } \\omega) & \\sum\\limits_{p \\in \\cal{P}} \\lambda_p \\leq \\ell & \\\\\n",
    " &  \\lambda_{p} \\in \\{ 0,1 \\} &\n",
    "\\end{array}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColGen Subproblem\n",
    "\n",
    "> Column reduced cost: $\\overline{c}_p = 1 - \\omega - \\sum\\limits_{v \\in V} \\pi_v . a_v$\n",
    "\n",
    "$$\n",
    "{\\large\n",
    "\\begin{array}{rll}\n",
    "\\max  &  \\sum\\limits_{v \\in V} \\pi_v . a_v &\\\\\n",
    "s.t. & & \\\\\n",
    " & a_{v} + a_{w} \\leq 1  &\\quad  d(v,w) > H + 1 \\\\\n",
    " &  a_{v} \\in \\{ 0,1 \\} & \\quad \\forall v \\in V\n",
    "\\end{array}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Variables for Problem 2 using Column Generation (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### SUB-PROBLEM Variables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Instance\n",
    "\n",
    "def graph_read(file_name):\n",
    "    global n, m, arc_i, arc_j, Adj, dist\n",
    "\n",
    "    f = open(file_name,'r+')\n",
    "\n",
    "    arc_i = {}\n",
    "    arc_j = {}\n",
    "    \n",
    "    infty_cost = 1.0\n",
    "\n",
    "    vertexSet = []\n",
    "    row = 0\n",
    "    for line in f.readlines():\n",
    "        item_data = line.split()\n",
    "        if (row == 0):\n",
    "            n = int(item_data[0])\n",
    "            print(\"Vertices\",n)\n",
    "\n",
    "        if (row == 1):\n",
    "            m = int(item_data[0])\n",
    "            print(\"Arestas\",m)\n",
    "            \n",
    "        if (row > 1):\n",
    "            i = row - 1\n",
    "            x = int(item_data[0])\n",
    "            arc_i[i] = x\n",
    "            if x not in vertexSet:\n",
    "                vertexSet.append(x)\n",
    "            x = int(item_data[1])\n",
    "            arc_j[i] = x\n",
    "            if x not in vertexSet:\n",
    "                vertexSet.append(x)\n",
    "            #print(i, arc_i[i], arc_j[i])\n",
    "        row += 1\n",
    "    f.close()\n",
    "\n",
    "    vertexP = {}\n",
    "    vertexN = {}\n",
    "    vertexSet.sort()\n",
    "    ind = 1\n",
    "    for v in vertexSet:\n",
    "        vertexP[ind] = v\n",
    "        vertexN[v] = ind\n",
    "        ind +=1\n",
    "        \n",
    "#     print(n)\n",
    "#     print(ind)\n",
    "    \n",
    "    #print vertexSet\n",
    "    #print \"         ------ jhskjehf \"\n",
    "    #print vertexP\n",
    "    #print \"         ------ jhskjehf \"\n",
    "    #print vertexN\n",
    "\n",
    "    listAdj = {}\n",
    "    for i in range(1,n+1):\n",
    "        listAdj[i] = []\n",
    "\n",
    "    Adj = {}\n",
    "    for i in range(1, n):\n",
    "        for j in range(i+1, n+1):\n",
    "            Adj[i,j] = 1\n",
    "\n",
    "    for l in range(1, m+1):\n",
    "        arc_i[l] = vertexN[arc_i[l]]\n",
    "        arc_j[l] = vertexN[arc_j[l]]\n",
    "        if arc_i[l] < arc_j[l]:\n",
    "            Adj[arc_i[l], arc_j[l]] = 0\n",
    "            listAdj[arc_i[l]].append(arc_j[l])\n",
    "            listAdj[arc_j[l]].append(arc_i[l])\n",
    "            \n",
    "#    for i in range(1,n+1):\n",
    "#        print 'List: ', i, listAdj[i]\n",
    "    \n",
    "    dist = {}\n",
    "    for s in range(1,n+1):    \n",
    "        for i in range(1,n+1):\n",
    "            dist[s,i] = -1\n",
    "        dist[s,s] = 0\n",
    "\n",
    "        q = []\n",
    "        q.append(s)\n",
    "        \n",
    "        while len(q)>0:\n",
    "            v = q[0]\n",
    "            q.remove(q[0])\n",
    "            for w in listAdj[v]:\n",
    "                if dist[s,w] == -1:\n",
    "                    dist[s,w] = dist[s,v] + 1\n",
    "                    q.append(w)\n",
    "                    \n",
    "#    for s in range(1,n+1):\n",
    "#        print s\n",
    "#        for v in range(1,n+1):\n",
    "#            print s,'->', v, ' : ',dist[s,v] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y_v variables which represent the belonging of vertex v to a cluster p.\n",
    "# If vertex v belongs to cluster a, then y_v == 1. Otherwise, y_v == 0.\n",
    "# Binary decision variable.\n",
    "\n",
    "def create_yv_vars_sub(model, yv):\n",
    "    global n, m, arc_i, arc_j, Adj\n",
    "    \n",
    "    for v in range(1, n+1):\n",
    "        yv[v] = model.addVar(obj=0.0, vtype=GRB.BINARY, name='y'+'_'+str(v))\n",
    "    model.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### MASTER-PROBLEM Variables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lamb_p variables which represent the belonging of cluster p to the subset of clusters that is minimum and.\n",
    "# a feasible solution to the problem of maximum connectivity.If cluster p belongs to the solution, then lamb_v == 1. \n",
    "# Otherwise, lamb_p == 0.\n",
    "# Decision variable.\n",
    "\n",
    "def create_lamb_vars_master(model, lamb):\n",
    "    global n, m, arc_i, arc_j, Adj\n",
    "    \n",
    "    for p in range(1, n+1):\n",
    "        lamb[p] = model.addVar(obj=1.0, vtype=GRB.CONTINUOUS, name='lamb'+'_'+str(p))\n",
    "    model.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Constraints for Problem 2 using Column Generation (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### SUB-PROBLEM Constraints \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColGen Subprob Create Conflict Constraints\n",
    "\n",
    "def create_conf_sub_constr_sub(model, conf, yv):\n",
    "    global n, m, arc_i, arc_j, Adj, dist, H\n",
    "    print(\"H: \",H)\n",
    "    for i in range(1, n):\n",
    "        for j in range(i+1, n+1):\n",
    "            if dist[i,j] > H + 1:\n",
    "                conf[i,j] = model.addConstr(yv[i] + yv[j] <= 1, name='conf_'+str(i)+'_'+str(j))                                            \n",
    "    \n",
    "    model.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### MASTER-PROBLEM Constraints \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColGen Master Set Part Constraints\n",
    "\n",
    "def create_sp_constr_master(model, part, lamb, v_lamb):\n",
    "    global n, m, arc_i, arc_j, Adj\n",
    "\n",
    "    \n",
    "    for v in range(1, n+1):\n",
    "        v_lamb[v] = [v]\n",
    "        part[v] = model.addConstr(lamb[v] == 1, name='part_'+str(v))                                            \n",
    "    \n",
    "    model.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColGen Master Cardinality Constraints\n",
    "\n",
    "def create_card_constr_master(model, lamb):\n",
    "    global n, m, arc_i, arc_j, Adj, ell\n",
    "\n",
    "    \n",
    "    slack_card = model.addVar(obj=100.0, vtype=GRB.CONTINUOUS, name='slack')\n",
    "    card = model.addConstr(quicksum(lamb[v] for v in range(1,n+1)) - slack_card <= ell, name='card')                                            \n",
    "    \n",
    "    model.update()\n",
    "    \n",
    "    return(card)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Creation and Solver for the Sub-Problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub():\n",
    "    global yv, pi_v, conf, msub\n",
    "    yv = {}\n",
    "    pi_v = {}\n",
    "    conf = {}\n",
    "    create_yv_vars_sub(msub, yv)\n",
    "    create_conf_sub_constr_sub(msub, conf, yv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solvesub():\n",
    "    global yv, conf, msub, pi_v\n",
    "    \n",
    "    for v in range(1,n+1):\n",
    "        yv[v].setAttr('Obj', pi_v[v])\n",
    "\n",
    "    msub.optimize()\n",
    "    zp = msub.getObjective()\n",
    "    return zp.getValue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Solver for the Master Problem using the Column Generation described above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColGen Solve Linear Relaxation\n",
    "\n",
    "def solve_lp_master(timeLimit):\n",
    "    global yv, pi_v, conf, msub\n",
    "    \n",
    "    Epsilon = 0.001\n",
    "    master = Model()\n",
    "    lamb = {}\n",
    "    v_lamb = {}\n",
    "    \n",
    "    vars_tstart = tm.time()\n",
    "    create_lamb_vars_master(master, lamb)\n",
    "    print(\"Variable LAMBDA (Master) created (execution time = {:.4f}s).\".format(tm.time() - vars_tstart))\n",
    "\n",
    "    part = {}\n",
    "    vars_tstart = tm.time()\n",
    "    create_sp_constr_master(master, part, lamb, v_lamb)\n",
    "    print(\"Constraint Set Partition (Master) created (execution time = {:.4f}s).\".format(tm.time() - vars_tstart))\n",
    "\n",
    "    vars_tstart = tm.time()\n",
    "    card = create_card_constr_master(master, lamb)\n",
    "    print(\"Constraint Card (Master) created (execution time = {:.4f}s).\".format(tm.time() - vars_tstart))\n",
    "    \n",
    "    msub = Model()\n",
    "    \n",
    "\n",
    "    create_sub()\n",
    "    print(\"Subproblem created (execution time = {:.4f}s).\".format(tm.time() - vars_tstart))\n",
    "    \n",
    "    master.setParam('OutputFlag', 0)\n",
    "    master.setParam('TimeLimit', timeLimit)\n",
    "    msub.setParam('OutputFlag', 0)\n",
    "    msub.setParam('TimeLimit', timeLimit)\n",
    "    \n",
    "    # print(\"TimeLimit: {}\".format(timeLimit))\n",
    "    n_columns = n\n",
    "    not_opt = 1\n",
    "    total_time = 0.0\n",
    "    while not_opt > 0:\n",
    "        vars_tstart = tm.time()\n",
    "        if total_time > timeLimit:\n",
    "            master.update()\n",
    "            break\n",
    "        \n",
    "        not_opt = 0\n",
    "        master.optimize()\n",
    "        if master.status == GRB.INFEASIBLE:\n",
    "            return \"infeasible\"\n",
    "        \n",
    "        inc = tm.time() - vars_tstart\n",
    "        print(\"Time duration = {:.4f}s.\".format(inc))\n",
    "        total_time = total_time + inc\n",
    "        \n",
    "        if total_time > timeLimit:\n",
    "            print(\"Time limit reached\",total_time)\n",
    "            break\n",
    "        zd = master.getObjective()\n",
    "\n",
    "\n",
    "        for v in range(1,n+1):\n",
    "            pi_v[v] = -part[v].getAttr(\"Pi\")\n",
    "            \n",
    "        omega = card.getAttr(\"Pi\")\n",
    "\n",
    "        redcost = solvesub()\n",
    "        redcost = - redcost\n",
    "        \n",
    "        #msub.write(\"sub.lp\")\n",
    "        print ('N columns:', n_columns,\"/Redcost:\",redcost,\"Master V:\",zd.getValue())\n",
    "        if redcost >= 1 - omega + Epsilon:\n",
    "            not_opt = 1\n",
    "        \n",
    "            v_sol = msub.getAttr('X', yv)\n",
    "            #print v_sol\n",
    "            v_sol_r = [v for v in range(1,n+1) if v_sol[v] > 0.01]\n",
    "\n",
    "            n_columns += 1\n",
    "            lamb[n_columns] = master.addVar(obj=1.0, vtype=GRB.CONTINUOUS, name='lamb'+'_'+str(n_columns))\n",
    "            master.update()\n",
    "\n",
    "            v_lamb[n_columns] = []\n",
    "            for v in v_sol_r:\n",
    "                v_lamb[n_columns].append(v)\n",
    "                master.chgCoeff(part[v],lamb[n_columns], 1.0)\n",
    "            master.update()\n",
    "            \n",
    "        else:\n",
    "            not_opt = 0\n",
    "\n",
    "    master.write(\"mm.lp\")\n",
    "    print ('N columns:', n_columns)\n",
    "    \n",
    "    l_sol = master.getAttr('X', lamb)\n",
    "    #print v_sol\n",
    "    \n",
    "    l_sol_r = [r for r in range(1,n_columns+1) if l_sol[r] > 0.001]\n",
    "    print (l_sol_r)\n",
    "    \n",
    "    for r in l_sol_r:\n",
    "        print (r, l_sol[r])\n",
    "        col = master.getCol(lamb[r])\n",
    "        print (col)\n",
    "        print (v_lamb[r])\n",
    "    \n",
    "    \n",
    "    zd = master.getObjective()\n",
    "    print (\"Obj function:\",zd.getValue())\n",
    "    print(\"execution total_time\",total_time)\n",
    "    print(\"execution total_time= {:.4f}s.\".format(total_time))\n",
    "    return total_time\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Execute the cell below to use the Column Generation algorithm for Problem 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instance_path = \"instances/\"\n",
    "\n",
    "files = []\n",
    "timeLimits = []\n",
    "nClusters = [2, 16, 67]\n",
    "\n",
    "hFoundForCluster = [5, 15, 57]\n",
    "\n",
    "files.append(instance_path + \"as19990829.txt\") # 103-243\n",
    "timeLimits.append(60*60*4) # 4 horas\n",
    "\n",
    "# files.append(instance_path + \"as19981229.txt\") #493-1189\n",
    "# timeLimits.append(60*60*6) # 6 horas\n",
    "\n",
    "# files.append(instance_path + \"as19981230.txt\") #493-1189\n",
    "# timeLimits.append(60*60*6) # 6 horas\n",
    "\n",
    "\n",
    "# iterate over instances\n",
    "for i in range(0,len(files)):\n",
    "    # iterate over # of clusters\n",
    "\n",
    "    for j in range(0,len(nClusters)):\n",
    "        #H = startH\n",
    "        H = hFoundForCluster[j]\n",
    "        \n",
    "        #only for entering while\n",
    "        BEST_H = H + 1\n",
    "        \n",
    "        print(\"Instância:\", files[i],\" # de clusters:\",nClusters[j])\n",
    "        \n",
    "        #remove from while loop\n",
    "        ell = nClusters[j]\n",
    "        graph_read(files[i])\n",
    "        \n",
    "        lp_result = 0\n",
    "        remaining_time = timeLimits[i]\n",
    "        \n",
    "        firstTry = True\n",
    "        \n",
    "        while H != BEST_H:\n",
    "            \n",
    "            lp_result = solve_lp_master(remaining_time)\n",
    "            print(\"lp_result:\",lp_result)\n",
    "            if lp_result == \"infeasible\":\n",
    "                print(\"infeasible\")\n",
    "                \n",
    "                if (firstTry):\n",
    "                    print(\"Nao ha melhor H encontrado. Selecione um H inicial viável.\")\n",
    "                    break\n",
    "                \n",
    "                print(\"Melhor H encontrado por ora: \",BEST_H)\n",
    "                #let's go up\n",
    "                H = int((BEST_H + H) / 2)\n",
    "                \n",
    "            else:\n",
    "                print(\"feasible\")\n",
    "                #let's go down\n",
    "                BEST_H = H\n",
    "                H = int(BEST_H / 2)\n",
    "            \n",
    "            firstTry = False\n",
    "                \n",
    "            remaining_time = remaining_time - lp_result\n",
    "            print(\"Remaining Time:\",remaining_time)\n",
    "            if(remaining_time <= 0.0 or H <= 0):\n",
    "                print(\"Melhor H encontrado: \",BEST_H)    \n",
    "                break\n",
    "            \n",
    "            print(\"H was updated %d\"% (H))\n",
    "            #H = H - 1\n",
    "        print(\"### END OF WHILE!!!! ###\")\n",
    "        \n",
    "        #let's try last tentative with the last number, H == 0\n",
    "        #lp_result = solve_lp(remaining_time)\n",
    "        #if lp_result == \"infeasible\":\n",
    "        #    print(\"infeasible\")\n",
    "        #else:\n",
    "        #    BEST_H = H\n",
    "        \n",
    "        print(\"Melhor H encontrado: \",BEST_H) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras Formulações (Tentativas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulação Alternativa 01 para o Problema 2 (Clique Clustering Model - G=(V,E))\n",
    "## Clique Clustering Model - G=(V,E) - Fix # Clusters - Max conectividade\n",
    "\n",
    "\n",
    "$$\n",
    "{\\large\n",
    "\\begin{array}{rll}\n",
    "\\min  &  \\rho  &\\\\\n",
    "s.t. & & \\\\\n",
    " & d(v,w).\\delta_{vw} \\leq \\rho & \\quad \\forall (v,w) \\in V \\times V \\quad k = 1,\\ldots,n\\\\\n",
    " & \\sum\\limits_{k=1}^{n} (y_{vk} *\\ y_{wk})\\ =\\ \\delta_{vw}\\ &\\quad \\forall (v,w) \\in V \\times V\\\\\n",
    " & \\sum\\limits_{k=1}^{n} y_{vk}\\ =\\ 1 & \\quad \\forall v \\in V \\\\\n",
    " & \\sum\\limits_{k=1}^{n} (y_{vk}\\ *\\ z_{k})\\ =\\ 1 & \\quad \\forall v \\in V \\\\\n",
    " & \\sum\\limits_{v=1}^{n} y_{vk}\\ \\geq\\ z_{k}\\ & \\quad \\forall k = 1,\\ldots,n\\\\\n",
    " &  \\sum\\limits_{k=1}^{n} z_k \\leq \\ell &\\\\\n",
    " &  y_{vk} \\in \\{ 0,1 \\} &\\quad \\forall (v,k) \\in V \\times V\\ where\\ k = 1,\\ldots,n & \\\\\n",
    " &  z_{k} \\in \\{ 0,1 \\} &\\quad k = 1,\\ldots,n & \\\\\n",
    " &  \\delta_{vw} \\in \\{ 0,1 \\} &\\quad \\forall (v,w) \\in V \\times V & \\\\\n",
    "\\end{array}\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Variables for Problem 2 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create y_vk variables which represent the belonging of vertex v to the cluster k.\n",
    "# If vertex v belongs to cluster k, then y_vk == 1. Otherwise, y_vk == 0.\n",
    "# Binary decision variable.\n",
    "\n",
    "def create_yvk_vars_01(model, V):\n",
    "    n = len(V)\n",
    "    \n",
    "    y_vk = {}\n",
    "    \n",
    "    # For each vertex v and cluster k, vertex v belongs to cluster k (y_vk == 1) or not (y_vk == 0).\n",
    "    for k in range(1, n+1):\n",
    "        for v in range(1, n+1):\n",
    "            y_vk[v, k] = model.addVar(obj=0.0, vtype=GRB.BINARY, name='y_vk'+'_'+str(v)+str(k))\n",
    "    model.update()\n",
    "    return y_vk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create z_k variables which represent the inclusion of cluster k to the set of clusters composing the solution.\n",
    "# If cluster k belongs to the set of disjoint partitions of V, then z_k == 1. Otherwise, z_k == 0.\n",
    "# If z_k == 0, then no vertex is allocated to the cluster k and cluster k is excluded from the solution.\n",
    "\n",
    "def create_zk_vars_01(model, V):\n",
    "\n",
    "    z_k = {}\n",
    "    \n",
    "    for k in range(1, len(V) + 1):\n",
    "        z_k[k] = model.addVar(obj=0.0, vtype=GRB.BINARY, name='z'+'_'+str(k))\n",
    "    model.update()\n",
    "    return z_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create delta_vw binary variables which activates the diameter constraints dist(v, w) * d_vw <= rho, where rho\n",
    "# represents the maximum allowed diameter of a cluster and dist(v, w) the minimum distance between vertices v and w.\n",
    "#\n",
    "# Therefore:\n",
    "#    1. if delta_vw is 1, then vertices v and w belong to the same cluster, then dist(v, w) must be less or equal \n",
    "#       to rho.\n",
    "#    2. if delta_vw is 0, then vertices v and w don't belong to the same cluster, then dist(v, w) is multiplied by \n",
    "#       0 and this constraint doesn't regulate the dist(v, w).\n",
    "\n",
    "def create_d_vw_vars_01(model, V, dist):\n",
    "\n",
    "    n = len(V)\n",
    "    d_vw = {}\n",
    "    \n",
    "    for v in range(1, n):\n",
    "        for w in range(v+1, n + 1):\n",
    "            if((v, w) in dist):\n",
    "                d_vw[v, w] = model.addVar(obj=0.0, vtype=GRB.BINARY, name='delta_'+str(v)+\"_\"+str(w))\n",
    "    model.update()\n",
    "    return d_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create delta_vwk binary variables which activates the diameter constraints dist(v, w) * d_vwk <= rho, where rho\n",
    "# represents the maximum allowed diameter of a cluster and dist(v, w) the minimum distance between vertices v and w.\n",
    "#\n",
    "# Therefore:\n",
    "#    1. if delta_vwk is 1, then vertices v and w belong to the same cluster, then dist(v, w) must be less or equal \n",
    "#       to rho.\n",
    "#    2. if delta_vwk is 0, then vertices v and w don't belong to the same cluster, then dist(v, w) is multiplied by \n",
    "#       0 and this constraint doesn't regulate the dist(v, w).\n",
    "#\n",
    "# delta_vwk represents the status of belonging of vertices v and w to the cluster k. \n",
    "\n",
    "def create_d_vwk_vars_01(model, V, dist):\n",
    "\n",
    "    n = len(V)\n",
    "    d_vwk = {}\n",
    "    \n",
    "    for k in range(1, n + 1):\n",
    "        for v in range(1, n):\n",
    "            for w in range(v+1, n+1):\n",
    "                if((v, w) in dist):\n",
    "                    d_vwk[v, w, k] = model.addVar(obj=0.0, vtype=GRB.BINARY, name='delta_'+str(v)+\"_\"+str(w)+\"_\"+str(k))\n",
    "    model.update()\n",
    "    return d_vwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create rho variable which represent the maximum diameter allowed for any cluster. This diameter must be minimized.\n",
    "\n",
    "def create_h_var_01(model, V):\n",
    "\n",
    "    h = model.addVar(obj=1.0, vtype=GRB.INTEGER, name='rho_h')\n",
    "    \n",
    "    model.update()\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Constraints for Problem 2 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diameter-limit constraints which restricts a pair of vertices (v, w) to belong to the same cluster\n",
    "# only if the minimum distance between these vertices is at most h (variable rho), the objective function variable.\n",
    "# If the minimum distance between vertices v and w is greater than h (rho), then v or w belongs to cluster k\n",
    "# or v, w not in cluster k.\n",
    "\n",
    "def create_conf_vw_constraints_01(model, y_vk, d_vw, V, h, dist):\n",
    "\n",
    "    n = len(V)\n",
    "    total = 0\n",
    "    \n",
    "    conf_constrs = {}\n",
    "    conf_v_constrs = {}\n",
    "    conf_w_constrs = {}\n",
    "    dist_h_constrs = {}\n",
    "\n",
    "    for v in range(1, n):\n",
    "        for w in range(v+1, n+1):\n",
    "            if( (v, w) in d_vw ):\n",
    "                total = total + 1\n",
    "                constr_name = 'conf_constr_'+str(v)+'_'+str(w)\n",
    "                conf_constrs[v, w] = model.addConstr(quicksum(y_vk[v, k] * y_vk[w, k] for k in range(1, n+1)) == d_vw[v, w], name=constr_name)\n",
    "                constr_name = 'limit_distance_constr_'+str(v)+'_'+str(w)\n",
    "                dist_h_constrs[v, w] = model.addConstr(dist[v, w] * d_vw[v, w] <= h, name=constr_name)\n",
    "    \n",
    "    model.update()\n",
    "    print(\"\\nTotal conflict constraints created = \", total)\n",
    "    return conf_constrs, conf_v_constrs, conf_w_constrs, dist_h_constrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create upper bound constraints which assures that z_k will be assigned value 0 if a cluster holds no vertex.\n",
    "# If there are more than 0 vertices in cluster k, then z_k might assume values 0 or 1 according to this constraint.\n",
    "# However z_k must be 1 if exists more at least one vertex in cluster k. For this reason, the asgn_constraint is\n",
    "# created in the next cells.\n",
    "\n",
    "def create_up_constraints_01(model, y_vk, z_k, V):\n",
    "    n = len(V)\n",
    "    total = 0\n",
    "    up_constrs = {}\n",
    "    up_ref_constrs = {}\n",
    "\n",
    "    for v in range(1, n + 1):\n",
    "        total = total + 1\n",
    "        up_constrs[v] = model.addConstr(quicksum(y_vk[v, k] * z_k[k] for k in range(1, n+1)) == 1, name='up_constr_'+str(v))\n",
    "\n",
    "    for k in range(1, n + 1):\n",
    "        total = total + 1\n",
    "        up_ref_constrs[k] = model.addConstr(quicksum(y_vk[v, k] for v in range(1, n+1)) >= z_k[k], name='up_ref_constr_'+str(v)+'_'+str(k))\n",
    "    \n",
    "    model.update()\n",
    "    print(\"\\nTotal up constraints created = \", total)\n",
    "    return up_constrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Assignment constraints which restricts a vertex to belong only to one cluster at a time.\n",
    "# Each vertex belongs to one and one only cluster because partitions must be disjoint subsets of vertices.\n",
    "# If exist a vertex v that belongs to cluster k, then z_k must be assigned value 1. \n",
    "# Otherwise, z_k must be assigned 0. This is assured by the quicksum of the product y_vk[v, k] * z_k[k].\n",
    "    \n",
    "def create_asgn_constraints_01(model, y_vk, V):\n",
    "    n = len(V)\n",
    "    total = 0\n",
    "    asgn_constrs = {}\n",
    "    \n",
    "    for v in range(1, n + 1):\n",
    "        total = total + 1\n",
    "        constr_name = 'asgn_constr'+str(v)\n",
    "        asgn_constrs[v] = model.addConstr((quicksum(y_vk[v, k] for k in range(1, n + 1)) == 1), name=constr_name)\n",
    "    \n",
    "    model.update()\n",
    "    print(\"\\nTotal assignment constraints created = \", total)\n",
    "    return asgn_constrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create number of custers limit constraints which assures that there are only at most l clusters k (z_k == 1).\n",
    "# If z_k == 1, then cluster k exists in the solution. Otherwise, cluster k does not exist in the solution.\n",
    "# l is a given parameter.\n",
    "\n",
    "def create_nclusters_limit_constraints_01(model, z_k, V, l, en_exact_nc=False):\n",
    "    \n",
    "    n = len(V)\n",
    "    nclusters_limit_constrs = None\n",
    "    constr_name = 'nclusters_limit_constr'\n",
    "    \n",
    "    if en_exact_nc:\n",
    "        nclusters_limit_constrs = model.addConstr((quicksum(z_k[k] for k in range(1, n + 1)) == l), name=constr_name)\n",
    "    else:\n",
    "        nclusters_limit_constrs = model.addConstr((quicksum(z_k[k] for k in range(1, n + 1)) <= l), name=constr_name)\n",
    "    \n",
    "    model.update()\n",
    "    print(\"\\nTotal number clusters limit constraints created = 1\")\n",
    "    return nclusters_limit_constrs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create objective function.\n",
    "\n",
    "def setObjective_01(model, h):\n",
    "    model.setObjective(h, GRB.MINIMIZE)\n",
    "    model.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Primal-Dual Solver for Problem 2 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l => Maximum number of clusters\n",
    "\n",
    "def solveMaxConnClusters_01(V, E, vmap, graph, dist, l, timeLimit, en_exact_nc=False):\n",
    "    \n",
    "    n = len(V)\n",
    "    m = len(E)\n",
    "    \n",
    "    mp = Model()\n",
    "    \n",
    "    # Binary variables \n",
    "    y_vk = {}\n",
    "    y_vwk = {}\n",
    "    z_k = {}\n",
    "    d_vw = {}\n",
    "    \n",
    "    \n",
    "    # Constraints\n",
    "    conf_constrs = {}\n",
    "    conf_constrs_00 = {}\n",
    "    conf_v_constrs = {}\n",
    "    conf_w_constrs = {}\n",
    "    dist_h_constrs = {}\n",
    "    up_constrs = {}\n",
    "    asgn_constrs = {}\n",
    "    nclusters_limit_constrs = {}\n",
    "    \n",
    "    print(\"\\nl (Maximum Number of Clusters) = \", l)\n",
    "    \n",
    "    vars_tstart = tm.time()\n",
    "    \n",
    "    # Create variables y_vk for each vertex v and cluster k\n",
    "    # y_vk == 1 => vertex v belongs to cluster k\n",
    "    # y_vk == 0 => vertex v does not belong to cluster k\n",
    "    y_vk = create_yvk_vars_01(mp, V)\n",
    "    \n",
    "    ### yvklb_constrs = create_yvklb_constraint(mp, V, y_vk)\n",
    "    \n",
    "    # Create variables z_k for each disjoint cluster k\n",
    "    # z_k = 1 => cluster k exists.\n",
    "    # z_k = 0 => cluster k does not exist.\n",
    "    z_k = create_zk_vars_01(mp, V)\n",
    "    \n",
    "    # Create variables d_vw for each existing edge (v, w)\n",
    "    # d_vw = 1 => dist(v, w) <= h (rho)\n",
    "    # d_vw = 0 => dist(v, w) > h (rho).\n",
    "    d_vw = create_d_vw_vars_01(mp, V, dist)\n",
    "    \n",
    "    # Create objective variable h which represents the minimum diameter of clusters for having l clusters\n",
    "    h = create_h_var_01(mp, V)\n",
    "    \n",
    "    vars_exec_time = tm.time() - vars_tstart\n",
    "    print(\"\\nVariables created (execution time = {:.4f}s).\".format(vars_exec_time))\n",
    "    \n",
    "    constrs_tstart = tm.time()\n",
    "    #total = 0\n",
    "    # Create constraint for avoiding conflict (vertices farther than H + 1 belong to different cluster).\n",
    "    conf_constrs, conf_v_constrs, conf_w_constrs, dist_h_constrs = create_conf_vw_constraints_01(mp, y_vk, d_vw, V, h, dist)\n",
    "    \n",
    "    # Create upper bound constraints (y_vk <= z_k)\n",
    "    up_constrs = create_up_constraints_01(mp, y_vk, z_k, V)\n",
    "    \n",
    "    # Create assignment constraint (each vertex belongs to one and one only cluster)\n",
    "    asgn_constrs = create_asgn_constraints_01(mp, y_vk, V)\n",
    "    \n",
    "    # Create y_vk >= delta_vw for all (v, w) where v, w in V \n",
    "    # and delta_vw == 1 if and only if v and w belong to the same cluster.\n",
    "    # ydelta_vwk_constrs = create_ydelta_vwk_constraints(mp, V, y_vk, d_vw)\n",
    "    \n",
    "    ### l_lowerbound_constr = create_l_constraint(mp, V, z_k)\n",
    "    \n",
    "    # Create number of clusters limit constraint (there can't be more than l clusters)\n",
    "    nclusters_limit_constrs = create_nclusters_limit_constraints_01(mp, z_k, V, l, en_exact_nc)\n",
    "    \n",
    "    #print(\"TOTAL = \", total)\n",
    "    \n",
    "    setObjective_01(mp, h)\n",
    "    \n",
    "    constrs_exec_time = tm.time() - constrs_tstart\n",
    "    print(\"\\nConstraints created (execution time = {:.4f}s).\\n\".format(constrs_exec_time))\n",
    "    \n",
    "    # Time limit for searching an optimal solution.\n",
    "    try: \n",
    "        print(\"\\nTimeLimit: {}\\n\".format(timeLimit))\n",
    "\n",
    "        mp.write(\"mf_clust.lp\")\n",
    "        mp.setParam('TimeLimit', timeLimit)\n",
    "        mp.setParam('OutputFlag', 1)\n",
    "\n",
    "        print()\n",
    "        print(\"\\n####### SOLVER START #######\\n\")\n",
    "        solver_tstart = tm.time()\n",
    "        mp.optimize()\n",
    "        solver_exec_time = tm.time() - solver_tstart\n",
    "        print(\"\\nSolver finished (execution time = {:.4f}s)\\n\".format(solver_exec_time))\n",
    "        print(\"\\n####### SOLVER END #######\\n\")\n",
    "        print()\n",
    "\n",
    "\n",
    "        zp = mp.getObjective()\n",
    "\n",
    "        if(mp.getAttr(GRB.Attr.ModelSense) == 1):\n",
    "            print(\"Minimization\")\n",
    "        else:\n",
    "            print(\"Maximization\")\n",
    "        print(\"Objective function: {}\".format(zp))\n",
    "        print(\"TOTAL EXECUTION TIME = {:.4f}s\\n\".format(vars_exec_time + constrs_exec_time + solver_exec_time))\n",
    "\n",
    "        if mp.status == GRB.OPTIMAL:\n",
    "\n",
    "            mp.write(\"mp.lp\")\n",
    "            dvw_sol = mp.getAttr('X', d_vw)\n",
    "            yvk_sol = mp.getAttr('X', y_vk)\n",
    "            zk_sol = mp.getAttr('X', z_k)\n",
    "            yvk = {v:k for v in range(1, n + 1) for k in range(1, n + 1) if yvk_sol[v,k] > 0.001}\n",
    "\n",
    "            # FOR DEBUG PURPOSES ONLY.\n",
    "            #print(zk_sol)\n",
    "            #print(yvk)\n",
    "            #print()\n",
    "            #print(yvk_sol)\n",
    "            #print()\n",
    "            #print(dvw_sol)\n",
    "            #print()\n",
    "            #print(\"{}\\n\\n\".format(dist[2,4]))\n",
    "            #print(\"{}\\n\\n\".format(dist[2,5]))\n",
    "\n",
    "            clusters = {}\n",
    "\n",
    "            for v in yvk.keys():\n",
    "                clstr_index = yvk[v]\n",
    "                if clstr_index not in clusters.keys():\n",
    "                    clusters[clstr_index] = []\n",
    "                if v not in clusters[clstr_index]:\n",
    "                    clusters[clstr_index].append(v)\n",
    "\n",
    "            for v, w in dvw_sol.keys():\n",
    "                if( dvw_sol[v, w] == 1 ):\n",
    "                    #print(\"d_vw( v: {}, w: {} ) = {}\".format(v, w, dvw_sol[v, w]))\n",
    "                    #print(\"DISTANCE [ v: {}, w: {} ] = {}\".format(v, w, dist[v, w]))\n",
    "                    if yvk[v] != yvk[w]:\n",
    "                        print(\"ERROR: d_vw( v: {}, w: {}) == 1 but v in cluster {} and w in cluster {}\".format(v, w, yvk[v], yvk[w]))\n",
    "\n",
    "\n",
    "            #nx.write_gpickle([zp.getValue(), yvk, clusters],\"test.gpickle\")\n",
    "\n",
    "            return zp.getValue(), yvk, clusters\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"Model is NOT FEASIBLE or NOT OPTIMAL: Status Code = {}\\n\\n\".format(mp.status))\n",
    "\n",
    "            return None, None, None\n",
    "    except GurobiError as e:\n",
    "        print('Error code ' + str(e.errno) + \": \" + str(e))\n",
    "\n",
    "    except AttributeError:\n",
    "        print('Encountered an attribute error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Output of Results for Problem 2 (Clique Clustering Model - G=(V,E))   >>>  IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of color shades for each cluster and set the corresponding cluster color to each vertex.\n",
    "\n",
    "def computeColorMap_01(graph, clusters, vertex_cluster):\n",
    "    assert(isinstance(clusters, dict))\n",
    "    assert(isinstance(vertex_cluster, dict))\n",
    "    \n",
    "    if(not clusters or not vertex_cluster):\n",
    "        return None\n",
    "    \n",
    "    color_map = []\n",
    "    \n",
    "    cmap = cm.autumn\n",
    "    norm = Normalize(vmin=0,vmax=1)\n",
    "\n",
    "    ratio = 1.0 / len(clusters)\n",
    "    k_index = {}\n",
    "    k_counter = 1\n",
    "    for node in graph:\n",
    "        k = vertex_cluster[node]\n",
    "        #print(\"\\tNode: {} => k = {}\".format(node, k))\n",
    "        if k not in k_index.keys():\n",
    "            k_index[k] = k_counter\n",
    "            k_counter += 1\n",
    "        color_map.append(cmap(norm(k_index[k] * ratio)))\n",
    "    \n",
    "    return color_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSolution_01(zp, vertex_cluster, clusters, V, log_file_name=None):\n",
    "    assert(isinstance(vertex_cluster, dict))\n",
    "    assert(isinstance(clusters, dict))\n",
    "    \n",
    "    text_file = None\n",
    "    \n",
    "    if(isinstance(log_file_name, str)):\n",
    "        text_file = open(log_file_name, \"a\")\n",
    "        text_file.write(\"\\nMinimum Maximum Distance in Clusters: {}\\n\".format(zp))\n",
    "    print (\"\\nMinimum Maximum Distance in Clusters: \", zp)\n",
    "    \n",
    "    if(vertex_cluster != None and vertex_cluster):\n",
    "        print (\"\\nSolution (vertex_index, k_cluster_index): \\n\\n\\t{}\\n\".format(vertex_cluster))\n",
    "        if(text_file != None):\n",
    "            text_file.write(\"\\nSolution (vertex_index, k_cluster_index): \\n\\n\\t{}\\n\".format(vertex_cluster))\n",
    "    \n",
    "    if(isinstance(log_file_name, str)):\n",
    "        text_file = open(log_file_name, \"a\")\n",
    "        text_file.write(\"\\n\\n====> Clusters:\\n\\n\")\n",
    "    if(clusters != None and clusters):\n",
    "        for k,vertices in clusters.items():\n",
    "            print(\"\\tCluster #{} contains the following vertices: \\n\".format(k))\n",
    "            if(text_file != None):\n",
    "                text_file.write(\"\\tCluster #{} contains the following vertices: \\n\".format(k))\n",
    "            line_buffer = 0\n",
    "            for v in vertices:\n",
    "                if(line_buffer == 0):\n",
    "                    print(\"\\t\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]), end = '')\n",
    "                    if(text_file != None):\n",
    "                        text_file.write(\"\\t\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]))\n",
    "                else:\n",
    "                    print(\"\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]), end = '')\n",
    "                    if(text_file != None):\n",
    "                        text_file.write(\"\\tINDEX = {} ; vertex[{}] = {}\".format(v, v, V[v]))\n",
    "                line_buffer += 1\n",
    "                \n",
    "                # Blank line paragraph after printing 3 vertices.\n",
    "                if(line_buffer == 3):\n",
    "                    print()\n",
    "                    if(text_file != None):\n",
    "                        text_file.write(\"\\n\")\n",
    "                    line_buffer = 0\n",
    "            print(\"\\n\")\n",
    "            if(text_file != None):\n",
    "                text_file.write(\"\\n\")\n",
    "    \n",
    "    if(text_file != None):\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Execution of Primal-Dual Algorithm for Problem 2 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def solveProbClusterMaxConnect_01(file_path, list_L, en_exact_nc=False, timeLimit=5000, show_graph=False, log_file_name=None):\n",
    "    \n",
    "    ###################################\n",
    "    # file_path = \"t01.txt\"\n",
    "    ###################################\n",
    "    \n",
    "    ###################################\n",
    "    # Maximum number of clusters\n",
    "    # list_L = [2, 1, 3]\n",
    "    ###################################\n",
    "    \n",
    "    ###################################\n",
    "    # If True, solves to find exactly l clusters. Otherwise, solves for any number of clusters less than l.\n",
    "    # en_exact_nc = False\n",
    "    ###################################\n",
    "\n",
    "    ###################################\n",
    "    # timeLimit = 60*60*4\n",
    "    ###################################\n",
    "    \n",
    "    n, m, V, E, vmap, graph, dist = loadGraphInstance(file_path)\n",
    "    \n",
    "    print(\"\\n\\nInput file: {}\\n\".format(file_path))\n",
    "    \n",
    "    # Iterate over all maximum number of clusters provided. The problem is separately solved for each l.\n",
    "    for l in list_L:\n",
    "        \n",
    "        print(\"\\n=====================================================================\\n\")\n",
    "        print(\"++++++++++++++++++++++++ ITERATION FOR L = {} ++++++++++++++++++++++++\".format(l))\n",
    "        print(\"\\n=====================================================================\\n\")\n",
    "        print(\"l = \", l)\n",
    "        \n",
    "        opt_val = None\n",
    "        vertex_cluster = {}\n",
    "        clusters = {}\n",
    "\n",
    "        # Solve the problem of minimizing the diameter in clusters given a maximum number of cluster equal to l.\n",
    "        opt_val, vertex_cluster, clusters = solveMaxConnClusters_01(V, E, vmap, graph, dist, l, timeLimit, en_exact_nc)\n",
    "    \n",
    "        if(opt_val != None):\n",
    "            print(\"Opt MIN maximum distance between vertices in clusters = \", opt_val)\n",
    "    \n",
    "        ###################################\n",
    "        #for v, w in dist:\n",
    "            #print(\"DISTANCE [ v: {}, w: {} ] = {}\".format(v, w, dist[v, w]))\n",
    "        ###################################\n",
    "    \n",
    "        log_file_n = None\n",
    "        log_file = None\n",
    "        randomUID = None\n",
    "        \n",
    "        # Writes the header of the LOG FILE if a log file name has been provided.\n",
    "        if(isinstance(log_file_name, str)):\n",
    "            randomUID = ''.join(random.choice(string.ascii_lowercase) for i in range(10))\n",
    "            log_file_n = log_file_name + \"_l=\" + str(l) + \"_\" + randomUID + \".txt\"\n",
    "            print(\"\\nLOG FILE: {}\\n\".format(log_file_n))\n",
    "            log_file = open(log_file_n, \"a\")\n",
    "            log_file.write(\"\\n=====> LOG FILE FOR PROBLEM 02 MAX CONNECTIVITY CLUSTERING\\n\")\n",
    "            log_file.write(\"\\n\\nInput file: {}\\n\".format(file_path))\n",
    "            log_file.write(\"\\nITERATION FOR L = {} \\n\".format(l))\n",
    "            log_file.close()\n",
    "            log_file = None\n",
    "        \n",
    "        # Prints the found solution (also writes the solution to the log file if provided).\n",
    "        if(opt_val!=None and vertex_cluster!=None and clusters!=None):\n",
    "            if(log_file_n != None):\n",
    "                printSolution_01(opt_val, vertex_cluster, clusters, V, log_file_n)\n",
    "            else:\n",
    "                printSolution_01(opt_val, vertex_cluster, clusters, V)\n",
    "\n",
    "            if show_graph:\n",
    "                color_map = computeColorMap_01(graph, clusters, vertex_cluster)\n",
    "\n",
    "                #print(\"\\nColor Map: \\n\")\n",
    "                #print(\"\\t \", color_map)\n",
    "\n",
    "                visualizeGraph(graph, layout_attr='random', color_map=color_map, scale=1000, enable_edges=True, node_size=50)\n",
    "        else:\n",
    "            if(isinstance(log_file_name, str)):\n",
    "                log_file_n = log_file_name + \"_l=\" + str(l) + \"_\" + randomUID + \".txt\"\n",
    "                log_file = open(log_file_n, \"a\")\n",
    "                log_file.write(\"Model is NOT FEASIBLE or NOT OPTIMAL.\\n\\n\")\n",
    "                log_file.close()\n",
    "                log_file = None\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Execute the cell below to use the Primal-Dual algorithm for Problem 2 (Clique Clustering Model - G=(V,E)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Execute this cell to use the algorithm and find optimal solutions for the formulation above.\n",
    "\n",
    "# Path of the file containing the edges of the graph.\n",
    "file_paths = [\"instances/as19981229.txt\"] \n",
    "\n",
    "# Path of the file containing the log of the algorithm (results). If NONE, then no log file is generated.\n",
    "log_file_path = None #\"log_file_problem02\"\n",
    "\n",
    "# Maximum number of clusters having the minimum maximum diameter possible.\n",
    "L = [2, 16, 67]\n",
    "\n",
    "timeLimit = 60*60*6\n",
    "\n",
    "# Set the number of clusters to be exact if True. Otherwise, the number of cluster must be equal or less than l.\n",
    "en_exact_nc = True\n",
    "\n",
    "# Solve for each input file path in file_paths.\n",
    "for file_path in file_paths:\n",
    "    solveProbClusterMaxConnect(file_path=file_path, list_L=L, en_exact_nc=en_exact_nc, timeLimit=timeLimit,\n",
    "                               show_graph=True, log_file_name=log_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
